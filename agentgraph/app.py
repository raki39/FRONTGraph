"""
AgentGraph - Aplica√ß√£o principal com interface Gradio e LangGraph
Integrado com Celery + Redis + Flower para processamento ass√≠ncrono
"""
import asyncio
import logging
import gradio as gr
import tempfile
import os
import subprocess
import threading
import time
import atexit
from typing import List, Tuple, Optional, Dict
from PIL import Image

from agentgraph.graphs.main_graph import initialize_graph, get_graph_manager
from agentgraph.utils.config import (
    AVAILABLE_MODELS,
    REFINEMENT_MODELS,
    DEFAULT_MODEL,
    DEFAULT_TOP_K,
    GRADIO_SHARE,
    GRADIO_PORT,
    validate_config,
    is_langsmith_enabled,
    LANGSMITH_PROJECT,
    CELERY_ENABLED,
    CELERY_BROKER_URL,
    CELERY_RESULT_BACKEND,
    CELERY_WORKER_CONCURRENCY,
    CELERY_WORKER_COUNT,
    FLOWER_PORT,
    is_docker_environment,
    get_environment_info,
    get_redis_connection_url,
    REDIS_HOST,
    REDIS_PORT
)
from agentgraph.utils.object_manager import get_object_manager

# Configura√ß√£o de logging
logging.basicConfig(
    level=logging.INFO, 
    format='%(asctime)s - %(levelname)s - %(message)s'
)

# Vari√°veis globais
graph_manager = None
show_history_flag = False
connection_ready = False  # Controla se a conex√£o est√° pronta para uso
chat_blocked = False      # Controla se o chat est√° bloqueado durante carregamento

# Vari√°veis globais do Celery
celery_worker_process = None
flower_process = None
redis_process = None
celery_enabled = False
redis_available = False

# Vari√°vel global para armazenar a √∫ltima SQL query (para cria√ß√£o de tabelas)
_last_sql_query = None

def kill_redis_processes():
    """Finaliza processos Redis existentes"""
    try:
        if os.name == 'nt':  # Windows
            subprocess.run(
                ["taskkill", "/F", "/IM", "redis-server.exe"],
                capture_output=True,
                check=False  # N√£o falha se processo n√£o existir
            )
            logging.info("[REDIS] Processos Redis existentes finalizados")
    except Exception as e:
        logging.warning(f"[REDIS] Erro ao finalizar processos Redis: {e}")

def start_local_redis():
    """Inicia Redis local da pasta do projeto"""
    global redis_process

    try:
        # Finaliza processos Redis existentes primeiro
        kill_redis_processes()

        # Procura pelo execut√°vel do Redis na pasta do projeto (caminhos corretos)
        redis_paths = [
            ("redis-windows/redis-server.exe", "redis-windows/redis.windows.conf"),
            ("redis-windows\\redis-server.exe", "redis-windows\\redis.windows.conf"),  # Windows paths
            ("redis-server.exe", "redis.windows.conf"),
            ("Redis/redis-server.exe", "Redis/redis.windows.conf")
        ]

        redis_exe = None
        redis_conf = None

        # Debug: Verifica se pasta redis-windows existe
        if os.path.exists("redis-windows"):
            logging.info("[REDIS] Pasta redis-windows encontrada")
        else:
            logging.warning("[REDIS] Pasta redis-windows N√ÉO encontrada")

        for exe_path, conf_path in redis_paths:
            logging.info(f"[REDIS] Testando: {exe_path}")
            if os.path.exists(exe_path):
                redis_exe = exe_path
                # Verifica se arquivo de configura√ß√£o existe
                if os.path.exists(conf_path):
                    redis_conf = conf_path
                    logging.info(f"[REDIS] Encontrado arquivo de configura√ß√£o: {redis_conf}")
                else:
                    logging.warning(f"[REDIS] Arquivo de configura√ß√£o n√£o encontrado: {conf_path}")
                break

        if not redis_exe:
            logging.warning("[REDIS] Execut√°vel redis-server.exe n√£o encontrado na pasta do projeto")
            return False

        # Converte para caminhos absolutos (como no teste que funcionou)
        abs_exe_path = os.path.abspath(redis_exe)
        abs_conf_path = os.path.abspath(redis_conf) if redis_conf else None

        logging.info(f"[REDIS] Caminho absoluto execut√°vel: {abs_exe_path}")
        if abs_conf_path:
            logging.info(f"[REDIS] Caminho absoluto configura√ß√£o: {abs_conf_path}")

        # Monta comando com caminhos absolutos
        if abs_conf_path and os.path.exists(abs_conf_path):
            cmd = [abs_exe_path, abs_conf_path]
            logging.info(f"[REDIS] Iniciando Redis local com configura√ß√£o: {abs_exe_path} {abs_conf_path}")
        else:
            cmd = [abs_exe_path]
            logging.info(f"[REDIS] Iniciando Redis local sem configura√ß√£o: {abs_exe_path}")

        # Inicia Redis em background
        redis_process = subprocess.Popen(
            cmd,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            creationflags=subprocess.CREATE_NEW_CONSOLE if os.name == 'nt' else 0,
            cwd=os.getcwd()  # Usa diret√≥rio atual como no teste
        )

        # Aguarda um pouco para Redis inicializar
        time.sleep(3)

        if redis_process.poll() is None:
            logging.info("[REDIS] Redis local iniciado com sucesso")
            return True
        else:
            # Captura sa√≠da para debug
            try:
                stdout, stderr = redis_process.communicate(timeout=5)
                logging.error("[REDIS] Falha ao iniciar Redis local")
                logging.error(f"[REDIS] STDOUT: {stdout.decode().strip()}")
                logging.error(f"[REDIS] STDERR: {stderr.decode().strip()}")
                logging.error(f"[REDIS] Return code: {redis_process.returncode}")
            except:
                logging.error("[REDIS] Falha ao iniciar Redis local (timeout na comunica√ß√£o)")
            return False

    except Exception as e:
        logging.error(f"[REDIS] Erro ao iniciar Redis local: {e}")
        logging.error(f"[REDIS] Comando tentado: {' '.join(cmd) if 'cmd' in locals() else 'N/A'}")
        return False

def check_redis_availability():
    """Verifica se Redis est√° dispon√≠vel baseado no ambiente"""
    global redis_available

    try:
        import redis

        # Usa configura√ß√µes din√¢micas baseadas no ambiente
        redis_client = redis.Redis(host=REDIS_HOST, port=REDIS_PORT, db=0)
        redis_client.ping()
        redis_available = True

        env_info = get_environment_info()
        logging.info(f"[REDIS] Redis dispon√≠vel em {env_info['environment']}: {REDIS_HOST}:{REDIS_PORT}")
        return True
    except Exception as e:
        redis_available = False
        env_info = get_environment_info()
        logging.warning(f"[REDIS] Redis n√£o dispon√≠vel em {env_info['environment']}: {e}")
        return False

def start_celery_worker():
    """Inicia worker(s) do Celery baseado no ambiente"""
    global celery_worker_process

    try:
        import sys
        env_info = get_environment_info()

        # Nome √∫nico do worker baseado no timestamp (usado em ambos os ambientes)
        import time
        worker_name = f"worker-{int(time.time())}@agentgraph"

        if is_docker_environment():
            # Configura√ß√£o para Docker - m√∫ltiplos workers
            logging.info(f"[CELERY] Iniciando {CELERY_WORKER_COUNT} workers Docker com {CELERY_WORKER_CONCURRENCY} concurrency cada")

            # Pool baseado na vari√°vel de ambiente ou padr√£o
            pool_type = os.getenv("CELERY_POOL", "prefork")

            # Inicia m√∫ltiplos workers
            celery_worker_processes = []

            for worker_id in range(CELERY_WORKER_COUNT):
                worker_name_multi = f"worker-{worker_id}-{int(time.time())}@agentgraph"

                cmd = [
                    sys.executable, "-m", "celery",
                    "-A", "tasks",
                    "worker",
                    f"--concurrency={CELERY_WORKER_CONCURRENCY}",
                    f"--hostname={worker_name_multi}",
                    "--loglevel=INFO",
                    f"--pool={pool_type}",  # Pool din√¢mico
                    "--without-gossip",  # Desabilita gossip
                    "--without-mingle",  # Desabilita mingle
                    "--events"  # Habilita events explicitamente
                ]

                logging.info(f"[CELERY] Iniciando worker {worker_id+1}/{CELERY_WORKER_COUNT}: {worker_name_multi}")

                process = subprocess.Popen(
                    cmd,
                    stdout=subprocess.PIPE,
                    stderr=subprocess.STDOUT,
                    cwd=os.getcwd(),
                    text=True,
                    bufsize=1,
                    universal_newlines=True
                )

                celery_worker_processes.append(process)

            # Usa o primeiro processo para logs (compatibilidade)
            celery_worker_process = celery_worker_processes[0] if celery_worker_processes else None

            logging.info(f"[CELERY] Pool configurado: {pool_type}")
            logging.info(f"[CELERY] Total: {CELERY_WORKER_COUNT} workers x {CELERY_WORKER_CONCURRENCY} concurrency = {CELERY_WORKER_COUNT * CELERY_WORKER_CONCURRENCY} processos")

        else:
            # Configura√ß√£o para Windows - single worker com solo pool
            cmd = [
                sys.executable, "-m", "celery",
                "-A", "tasks",
                "worker",
                f"--concurrency={CELERY_WORKER_CONCURRENCY}",
                f"--hostname={worker_name}",  # Nome √∫nico tamb√©m no Windows
                "--loglevel=INFO",
                "--pool=solo"  # Single-thread para Windows
            ]

            logging.info(f"[CELERY] Iniciando worker √∫nico para Windows: {' '.join(cmd)}")

            celery_worker_process = subprocess.Popen(
                cmd,
                stdout=subprocess.PIPE,
                stderr=subprocess.STDOUT,
                cwd=os.getcwd(),
                text=True,
                bufsize=1,
                universal_newlines=True
            )

        # Aguarda um pouco para verificar se iniciou
        time.sleep(5)

        if celery_worker_process.poll() is None:
            logging.info("[CELERY] ‚úÖ Worker Celery iniciado com sucesso")

            # L√™ algumas linhas de output para verificar se est√° funcionando
            try:
                import threading
                def read_worker_output():
                    for line in iter(celery_worker_process.stdout.readline, ''):
                        if line.strip():
                            logging.info(f"[CELERY_WORKER] {line.strip()}")

                # Inicia thread para ler output do worker
                worker_thread = threading.Thread(target=read_worker_output, daemon=True)
                worker_thread.start()

            except Exception as e:
                logging.warning(f"[CELERY] N√£o foi poss√≠vel ler output do worker: {e}")

            return True
        else:
            # Worker falhou, captura erro
            try:
                stdout, stderr = celery_worker_process.communicate(timeout=5)
                logging.error("[CELERY] ‚ùå Falha ao iniciar worker Celery")
                logging.error(f"[CELERY] STDOUT: {stdout}")
                logging.error(f"[CELERY] STDERR: {stderr}")
            except:
                logging.error("[CELERY] ‚ùå Worker falhou e n√£o foi poss√≠vel capturar erro")
            return False

    except Exception as e:
        logging.error(f"[CELERY] Erro ao iniciar worker: {e}")
        logging.error(f"[CELERY] Comando tentado: {' '.join(cmd) if 'cmd' in locals() else 'N/A'}")
        logging.error(f"[CELERY] Diret√≥rio atual: {os.getcwd()}")

        # Tenta verificar se celery est√° instalado
        try:
            import celery
            logging.info(f"[CELERY] Celery instalado na vers√£o: {celery.__version__}")
        except ImportError:
            logging.error("[CELERY] Celery n√£o est√° instalado!")

        return False

def start_flower_monitoring():
    """Inicia Flower para monitoramento baseado no ambiente"""
    global flower_process

    try:
        import sys
        env_info = get_environment_info()

        cmd = [
            sys.executable, "-m", "celery",
            "-A", "tasks",
            "flower",
            f"--port={FLOWER_PORT}"
        ]

        if is_docker_environment():
            # No Docker, adiciona configura√ß√µes espec√≠ficas
            cmd.extend([
                "--broker=redis://redis:6379/0",
                "--address=0.0.0.0",  # Permite acesso externo no Docker
                "--basic_auth=admin:admin",  # Autentica√ß√£o b√°sica
                "--auto_refresh=False"  # Desabilita auto-refresh para reduzir overhead
            ])
            logging.info(f"[FLOWER] Iniciando Flower para Docker: {' '.join(cmd)}")

            flower_process = subprocess.Popen(
                cmd,
                stdout=subprocess.PIPE,
                stderr=subprocess.STDOUT,
                cwd=os.getcwd(),
                text=True,
                bufsize=1,
                universal_newlines=True
            )
        else:
            # No Windows, usa console separado
            logging.info(f"[FLOWER] Iniciando Flower para Windows: {' '.join(cmd)}")

            flower_process = subprocess.Popen(
                cmd,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                creationflags=subprocess.CREATE_NEW_CONSOLE if os.name == 'nt' else 0,
                cwd=os.getcwd()
            )

        # Aguarda um pouco para verificar se iniciou
        time.sleep(3)

        if flower_process.poll() is None:
            logging.info(f"[FLOWER] Flower iniciado em http://localhost:{FLOWER_PORT}")
            return True
        else:
            logging.error("[FLOWER] Falha ao iniciar Flower")
            return False

    except Exception as e:
        logging.error(f"[FLOWER] Erro ao iniciar Flower: {e}")
        return False

def initialize_celery_system():
    """Inicializa sistema Celery completo baseado no ambiente"""
    global celery_enabled

    # Verifica se Celery est√° habilitado na configura√ß√£o
    if not CELERY_ENABLED:
        logging.info("[CELERY_INIT] Celery desabilitado na configura√ß√£o")
        celery_enabled = False
        return False

    env_info = get_environment_info()
    logging.info(f"[CELERY_INIT] Inicializando sistema Celery para {env_info['environment']}...")

    # 1. Verificar Redis baseado no ambiente
    if not check_redis_availability():
        if is_docker_environment():
            # No Docker, Redis deve estar dispon√≠vel como servi√ßo
            logging.error("[CELERY_INIT] Redis n√£o dispon√≠vel no Docker - verifique docker-compose.yml")
            celery_enabled = False
            return False
        else:
            # No Windows, tenta iniciar Redis local
            logging.info("[CELERY_INIT] Redis n√£o dispon√≠vel, tentando iniciar Redis local...")

            if start_local_redis():
                # Aguarda Redis inicializar e testa novamente
                time.sleep(2)
                if not check_redis_availability():
                    logging.warning("[CELERY_INIT] Redis local iniciado mas n√£o conecta - Celery desabilitado")
                    celery_enabled = False
                    return False
            else:
                logging.warning("[CELERY_INIT] N√£o foi poss√≠vel iniciar Redis local - Celery desabilitado")
                celery_enabled = False
                return False

    # 2. Iniciar Worker
    if not start_celery_worker():
        logging.warning("[CELERY_INIT] Worker n√£o iniciou - Celery desabilitado")
        celery_enabled = False
        return False

    # 3. Iniciar Flower
    if not start_flower_monitoring():
        logging.warning("[CELERY_INIT] Flower n√£o iniciou - Continuando sem monitoramento")
        # Flower √© opcional, n√£o desabilita Celery

    # Verificar se worker est√° realmente ativo
    time.sleep(3)  # Aguarda worker inicializar
    if verify_worker_active():
        logging.info("[CELERY_INIT] ‚úÖ Worker verificado e ativo!")
    else:
        logging.warning("[CELERY_INIT] ‚ö†Ô∏è Worker pode n√£o estar ativo")

    celery_enabled = True
    logging.info("[CELERY_INIT] Sistema Celery inicializado com sucesso!")
    return True

def verify_worker_active():
    """Verifica se worker Celery est√° ativo"""
    try:
        from celery import Celery

        # Conecta ao Celery
        celery_app = Celery(
            'test',
            broker=CELERY_BROKER_URL,
            backend=CELERY_RESULT_BACKEND
        )

        # Verifica workers ativos
        inspect = celery_app.control.inspect()
        active_workers = inspect.active()

        if active_workers:
            worker_names = list(active_workers.keys())
            logging.info(f"[CELERY_VERIFY] ‚úÖ Workers ativos: {worker_names}")
            return True
        else:
            logging.warning("[CELERY_VERIFY] ‚ùå Nenhum worker ativo encontrado")
            return False

    except Exception as e:
        logging.error(f"[CELERY_VERIFY] Erro ao verificar workers: {e}")
        return False

def cleanup_celery_processes():
    """Limpa processos do Celery ao encerrar"""
    global celery_worker_process, flower_process, redis_process

    logging.info("[CLEANUP] Encerrando processos Celery...")

    if celery_worker_process:
        try:
            celery_worker_process.terminate()
            celery_worker_process.wait(timeout=10)
            logging.info("[CLEANUP] Worker Celery encerrado")
        except Exception as e:
            logging.error(f"[CLEANUP] Erro ao encerrar worker: {e}")
            try:
                celery_worker_process.kill()
            except:
                pass

    if flower_process:
        try:
            flower_process.terminate()
            flower_process.wait(timeout=5)
            logging.info("[CLEANUP] Flower encerrado")
        except Exception as e:
            logging.error(f"[CLEANUP] Erro ao encerrar Flower: {e}")
            try:
                flower_process.kill()
            except:
                pass

    if redis_process:
        try:
            redis_process.terminate()
            redis_process.wait(timeout=5)
            logging.info("[CLEANUP] Redis local encerrado")
        except Exception as e:
            logging.error(f"[CLEANUP] Erro ao encerrar Redis: {e}")
            try:
                redis_process.kill()
            except:
                pass

    # For√ßa finaliza√ß√£o de todos os processos Redis
    try:
        if os.name == 'nt':  # Windows
            subprocess.run(
                ["taskkill", "/F", "/IM", "redis-server.exe"],
                capture_output=True,
                check=False
            )
            logging.info("[CLEANUP] Processos Redis finalizados via taskkill")
    except Exception as e:
        logging.warning(f"[CLEANUP] Erro ao finalizar Redis via taskkill: {e}")

async def initialize_app():
    """Inicializa a aplica√ß√£o"""
    global graph_manager, connection_ready

    try:
        # Valida configura√ß√µes
        validate_config()

        # Inicializa sistema Celery (opcional)
        initialize_celery_system()

        # Debug: Status final do Celery
        logging.info(f"[INIT] Status final celery_enabled: {celery_enabled}")
        logging.info(f"[INIT] CELERY_ENABLED config: {CELERY_ENABLED}")

        # Inicializa o grafo
        graph_manager = await initialize_graph()

        # Inicializa como conectado (base padr√£o j√° carregada)
        connection_ready = True

        # Informa sobre o status do LangSmith
        if is_langsmith_enabled():
            logging.info(f"‚úÖ LangSmith habilitado - Projeto: '{LANGSMITH_PROJECT}'")
            logging.info("üîç Traces ser√£o enviados para LangSmith automaticamente")
        else:
            logging.info("‚ÑπÔ∏è LangSmith n√£o configurado - Executando sem observabilidade")

        # Registra fun√ß√£o de cleanup para encerramento
        atexit.register(cleanup_celery_processes)

        logging.info("Aplica√ß√£o inicializada com sucesso")
        return True

    except Exception as e:
        logging.error(f"Erro ao inicializar aplica√ß√£o: {e}")
        return False

def run_async(coro):
    """Executa corrotina de forma s√≠ncrona"""
    try:
        loop = asyncio.get_event_loop()
    except RuntimeError:
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
    
    return loop.run_until_complete(coro)

def chatbot_response(user_input: str, selected_model: str, advanced_mode: bool = False, processing_enabled: bool = False, processing_model: str = "GPT-4o-mini", connection_type: str = "csv", postgresql_config: Optional[Dict] = None, selected_table: str = None, single_table_mode: bool = False, top_k: int = 10) -> Tuple[str, Optional[str]]:
    """
    Processa resposta do chatbot usando LangGraph

    Args:
        user_input: Entrada do usu√°rio
        selected_model: Modelo LLM selecionado
        advanced_mode: Se deve usar refinamento avan√ßado
        processing_enabled: Se o Processing Agent est√° habilitado
        processing_model: Modelo para o Processing Agent
        connection_type: Tipo de conex√£o ("csv" ou "postgresql")
        postgresql_config: Configura√ß√£o postgresql (se aplic√°vel)
        selected_table: Tabela selecionada (para postgresql)
        single_table_mode: Se deve usar apenas uma tabela (postgresql)
        top_k: N√∫mero m√°ximo de resultados (LIMIT) para queries SQL

    Returns:
        Tupla com (resposta_texto, caminho_imagem_grafico)
    """
    global graph_manager

    if not graph_manager:
        return "‚ùå Sistema n√£o inicializado. Tente recarregar a p√°gina.", None

    try:
        # Log simples
        logging.info(f"[CHATBOT] Usando Celery: {celery_enabled}")
        logging.info(f"[CHATBOT] üìä TOP_K para LangGraph: {top_k}")

        # Processa query atrav√©s do LangGraph
        result = run_async(graph_manager.process_query(
            user_input=user_input,
            selected_model=selected_model,
            advanced_mode=advanced_mode,
            processing_enabled=processing_enabled,
            processing_model=processing_model,
            connection_type=connection_type,
            postgresql_config=postgresql_config,
            selected_table=selected_table,
            single_table_mode=single_table_mode,
            top_k=top_k,
            use_celery=celery_enabled
        ))

        response_text = result.get("response", "Erro ao processar resposta")
        graph_image_path = None
        show_create_table_btn = False

        # Captura SQL query para uso posterior na cria√ß√£o de tabelas
        sql_query = result.get("sql_query_extracted") or result.get("sql_query")
        if sql_query and connection_type == "postgresql":
            # Armazena a SQL query globalmente para uso no modal
            global _last_sql_query
            _last_sql_query = sql_query
            show_create_table_btn = True
            logging.info(f"[RESPOND] ‚úÖ SQL query capturada para cria√ß√£o de tabela: {sql_query[:50]}...")
            logging.info(f"[RESPOND] ‚úÖ Bot√£o de criar tabela ser√° mostrado")
        else:
            logging.info(f"[RESPOND] ‚ùå Bot√£o de criar tabela n√£o ser√° mostrado (SQL: {bool(sql_query)}, Conn: {connection_type})")

        # Verifica se foi gerado um gr√°fico
        if result.get("graph_generated", False) and result.get("graph_image_id"):
            graph_image_path = save_graph_image_to_temp(result["graph_image_id"])

            # Adiciona informa√ß√£o sobre o gr√°fico na resposta
            if graph_image_path:
                graph_type = result.get("graph_type", "gr√°fico")
                response_text += f"\n\nüìä **Gr√°fico gerado**: {graph_type.replace('_', ' ').title()}"

        return response_text, graph_image_path, gr.update(visible=show_create_table_btn)

    except Exception as e:
        error_msg = f"Erro no chatbot: {e}"
        logging.error(error_msg)
        logging.error(f"Detalhes do erro: {type(e).__name__}: {str(e)}")
        return error_msg, None

def save_graph_image_to_temp(graph_image_id: str) -> Optional[str]:
    """
    Salva imagem do gr√°fico em arquivo tempor√°rio para exibi√ß√£o no Gradio

    Args:
        graph_image_id: ID da imagem no ObjectManager

    Returns:
        Caminho do arquivo tempor√°rio ou None se falhar
    """
    try:
        obj_manager = get_object_manager()
        graph_image = obj_manager.get_object(graph_image_id)

        if graph_image and isinstance(graph_image, Image.Image):
            # Cria arquivo tempor√°rio
            temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.png')
            graph_image.save(temp_file.name, format='PNG')
            temp_file.close()

            logging.info(f"[GRADIO] Gr√°fico salvo em: {temp_file.name}")
            return temp_file.name

    except Exception as e:
        logging.error(f"[GRADIO] Erro ao salvar gr√°fico: {e}")

    return None

def handle_csv_upload(file) -> str:
    """
    Processa upload de arquivo csv

    Args:
        file: Arquivo enviado pelo Gradio

    Returns:
        Mensagem de feedback
    """
    global graph_manager

    if not graph_manager:
        return "‚ùå Sistema n√£o inicializado."

    if not file:
        return "‚ùå Nenhum arquivo selecionado."

    try:
        # Log detalhado do arquivo recebido
        logging.info(f"[UPLOAD] Arquivo recebido: {file}")
        logging.info(f"[UPLOAD] Nome do arquivo: {file.name}")
        logging.info(f"[UPLOAD] Tipo do arquivo: {type(file)}")

        # Verifica se o arquivo existe
        import os
        if not os.path.exists(file.name):
            return f"‚ùå Arquivo n√£o encontrado: {file.name}"

        # Verifica se √© um arquivo csv
        if not file.name.lower().endswith('.csv'):
            return "‚ùå Por favor, selecione um arquivo csv v√°lido."

        # Verifica o tamanho do arquivo
        file_size = os.path.getsize(file.name)
        file_size_mb = file_size / (1024 * 1024)
        file_size_gb = file_size / (1024 * 1024 * 1024)

        if file_size_gb >= 1:
            size_str = f"{file_size_gb:.2f} GB"
        else:
            size_str = f"{file_size_mb:.2f} MB"

        logging.info(f"[UPLOAD] Tamanho do arquivo: {file_size} bytes ({size_str})")

        if file_size == 0:
            return "‚ùå O arquivo est√° vazio."

        if file_size > 5 * 1024 * 1024 * 1024:  # 5GB
            return "‚ùå Arquivo muito grande. M√°ximo permitido: 5GB."

        # Aviso para arquivos grandes
        if file_size_mb > 100:
            logging.info(f"[UPLOAD] Arquivo grande detectado ({size_str}). Processamento pode demorar...")
            return f"‚è≥ Processando arquivo grande ({size_str}). Aguarde..."

        # Processa upload atrav√©s do CustomNodeManager
        logging.info(f"[UPLOAD] Iniciando processamento do arquivo: {file.name}")
        result = run_async(graph_manager.custom_node_manager.handle_csv_upload(file.name, graph_manager.object_manager))

        # Atualiza IDs do sistema se upload foi bem-sucedido
        if result.get("success") and result.get("engine_id") and result.get("db_id"):
            graph_manager.engine_id = result["engine_id"]
            graph_manager.db_id = result["db_id"]

            # Cria novo agente SQL
            from agentgraph.agents.sql_agent import SQLAgentManager
            new_db = graph_manager.object_manager.get_database(graph_manager.db_id)
            if not new_db:
                logging.error(f"[UPLOAD] Banco de dados n√£o encontrado com ID: {graph_manager.db_id}")
                return "‚ùå Erro: Banco de dados n√£o encontrado ap√≥s upload"

            top_k = graph_manager.object_manager.get_global_config('top_k', 10)
            new_sql_agent = SQLAgentManager(
                db=new_db,
                model_name="gpt-4o-mini",
                single_table_mode=False,
                selected_table=None,
                top_k=top_k
            )
            graph_manager.agent_id = graph_manager.object_manager.store_sql_agent(new_sql_agent, graph_manager.db_id)

            # Limpa cache
            cache_manager = graph_manager.object_manager.get_cache_manager(graph_manager.cache_id)
            if cache_manager:
                cache_manager.clear_cache()

            logging.info("[UPLOAD] Sistema atualizado com novo CSV")

        logging.info(f"[UPLOAD] Resultado do processamento: {result}")
        return result.get("message", "Erro no upload")

    except Exception as e:
        error_msg = f"‚ùå Erro ao processar upload: {e}"
        logging.error(error_msg)
        logging.error(f"[UPLOAD] Detalhes do erro: {type(e).__name__}: {str(e)}")
        import traceback
        logging.error(f"[UPLOAD] Traceback: {traceback.format_exc()}")
        return error_msg

def reset_system() -> str:
    """
    Reseta o sistema ao estado inicial
    
    Returns:
        Mensagem de feedback
    """
    global graph_manager
    
    if not graph_manager:
        return "‚ùå Sistema n√£o inicializado."
    
    try:
        # Reseta sistema atrav√©s do CustomNodeManager
        result = run_async(graph_manager.custom_node_manager.reset_system(
            graph_manager.engine_id,
            graph_manager.agent_id,
            graph_manager.cache_id
        ))

        # Atualiza IDs se reset foi bem-sucedido
        if result.get("success"):
            graph_manager.engine_id = result.get("engine_id", graph_manager.engine_id)
            graph_manager.agent_id = result.get("agent_id", graph_manager.agent_id)
            logging.info("[RESET] Sistema resetado com sucesso")
        
        return result.get("message", "Erro no reset")
        
    except Exception as e:
        error_msg = f"‚ùå Erro ao resetar sistema: {e}"
        logging.error(error_msg)
        return error_msg

def handle_postgresql_connection(host: str, port: str, database: str, username: str, password: str) -> str:
    """
    Processa conex√£o postgresql

    Args:
        host: Host do postgresql
        port: Porta do postgresql
        database: Nome do banco
        username: Nome de usu√°rio
        password: Senha

    Returns:
        Mensagem de feedback
    """
    global graph_manager

    if not graph_manager:
        return "‚ùå Sistema n√£o inicializado."

    try:
        # Valida campos obrigat√≥rios
        if not all([host, port, database, username, password]):
            return "‚ùå Todos os campos s√£o obrigat√≥rios para conex√£o postgresql."

        # Valida porta
        try:
            port_int = int(port)
            if port_int < 1 or port_int > 65535:
                return "‚ùå Porta deve estar entre 1 e 65535."
        except ValueError:
            return "‚ùå Porta deve ser um n√∫mero v√°lido."

        # Prepara configura√ß√£o postgresql
        postgresql_config = {
            "host": host.strip(),
            "port": port_int,
            "database": database.strip(),
            "username": username.strip(),
            "password": password
        }

        # Cria estado inicial para a conex√£o
        initial_state = {
            "user_input": "Conectar postgresql",
            "selected_model": "gpt-4o-mini",
            "advanced_mode": False,
            "processing_enabled": False,
            "processing_model": "gpt-4o-mini",
            "connection_type": "postgresql",
            "postgresql_config": postgresql_config,
            "selected_table": None,
            "single_table_mode": False
        }

        # Processa conex√£o atrav√©s do CustomNodeManager
        logging.info(f"[POSTGRESQL] Iniciando conex√£o: {host}:{port}/{database}")
        result = run_async(graph_manager.custom_node_manager.handle_postgresql_connection(initial_state))

        # Atualiza sistema se conex√£o foi bem-sucedida
        if result.get("success"):
            graph_manager.engine_id = result.get("engine_id")
            graph_manager.db_id = result.get("db_id")

            # Cria novo agente SQL com configura√ß√µes do estado
            from agentgraph.agents.sql_agent import SQLAgentManager
            new_db = graph_manager.object_manager.get_database(graph_manager.db_id)
            if not new_db:
                logging.error(f"[POSTGRESQL] Banco de dados n√£o encontrado com ID: {graph_manager.db_id}")
                return "‚ùå Erro: Banco de dados n√£o encontrado ap√≥s conex√£o PostgreSQL"

            single_table_mode = initial_state.get("single_table_mode", False)
            selected_table = initial_state.get("selected_table")
            selected_model = initial_state.get("selected_model", "gpt-4o-mini")
            top_k = initial_state.get("top_k", 10)

            new_sql_agent = SQLAgentManager(
                db=new_db,
                model_name=selected_model,
                single_table_mode=single_table_mode,
                selected_table=selected_table,
                top_k=top_k
            )

            graph_manager.agent_id = graph_manager.object_manager.store_sql_agent(new_sql_agent, graph_manager.db_id)

            # Armazena metadados de conex√£o
            connection_info = result.get("connection_info", {})
            graph_manager.object_manager.store_connection_metadata(graph_manager.db_id, connection_info)

            # Limpa cache
            cache_manager = graph_manager.object_manager.get_cache_manager(graph_manager.cache_id)
            if cache_manager:
                cache_manager.clear_cache()

            logging.info("[POSTGRESQL] Sistema atualizado com nova conex√£o PostgreSQL")

        logging.info(f"[POSTGRESQL] Resultado da conex√£o: {result}")
        return result.get("message", "Erro na conex√£o postgresql")

    except Exception as e:
        error_msg = f"‚ùå Erro ao conectar postgresql: {e}"
        logging.error(error_msg)
        logging.error(f"[POSTGRESQL] Detalhes do erro: {type(e).__name__}: {str(e)}")
        return error_msg

def toggle_advanced_mode(enabled: bool) -> str:
    """
    Alterna modo avan√ßado usando n√≥ espec√≠fico

    Args:
        enabled: Se deve habilitar modo avan√ßado

    Returns:
        Mensagem de status
    """
    global graph_manager

    if not graph_manager:
        return "‚ùå Sistema n√£o inicializado."

    return run_async(graph_manager.custom_node_manager.toggle_advanced_mode(enabled))

def toggle_history():
    """Alterna exibi√ß√£o do hist√≥rico usando n√≥ espec√≠fico"""
    global show_history_flag, graph_manager

    show_history_flag = not show_history_flag

    if show_history_flag and graph_manager:
        return run_async(graph_manager.custom_node_manager.get_history(graph_manager.cache_id))
    else:
        return {}

def apply_top_k(top_k_value: int) -> str:
    """
    Aplica novo valor de TOP_K e for√ßa recria√ß√£o do agente SQL

    Args:
        top_k_value: Novo valor de TOP_K

    Returns:
        Mensagem de feedback
    """
    global graph_manager

    if not graph_manager:
        return "‚ùå Sistema n√£o inicializado."

    try:
        # Valida o valor
        if not isinstance(top_k_value, (int, float)) or top_k_value < 1:
            return "‚ùå TOP_K deve ser um n√∫mero maior que 0."

        top_k_value = int(top_k_value)

        if top_k_value > 10000:
            return "‚ùå TOP_K muito alto. M√°ximo permitido: 10.000."

        # For√ßa recria√ß√£o do agente SQL com novo TOP_K usando n√≥ espec√≠fico
        result = run_async(graph_manager.custom_node_manager.force_recreate_agent(
            agent_id=graph_manager.agent_id,
            top_k=top_k_value
        ))

        if result.get("success", False):
            # IMPORTANTE: Atualizar TOP_K no ObjectManager para o Celery
            if hasattr(graph_manager, 'object_manager') and graph_manager.object_manager:
                try:
                    # Atualiza configura√ß√£o global do TOP_K no ObjectManager
                    graph_manager.object_manager.update_global_config('top_k', top_k_value)
                    logging.info(f"[APPLY_TOP_K] TOP_K {top_k_value} atualizado no ObjectManager para Celery")
                except Exception as e:
                    logging.warning(f"[APPLY_TOP_K] Erro ao atualizar ObjectManager: {e}")

            return f"‚úÖ TOP_K atualizado para {top_k_value}. Agente SQL recriado e configura√ß√£o salva para Celery."
        else:
            return f"‚ùå Erro ao aplicar TOP_K: {result.get('message', 'Erro desconhecido')}"

    except Exception as e:
        error_msg = f"‚ùå Erro ao aplicar TOP_K: {e}"
        logging.error(error_msg)
        return error_msg

def respond(message: str, chat_history: List[Dict[str, str]], selected_model: str, advanced_mode: bool, processing_enabled: bool = False, processing_model: str = "GPT-4o-mini", connection_type: str = "csv", postgresql_config: Optional[Dict] = None, selected_table: str = None, single_table_mode: bool = False, top_k: int = 10):
    """
    Fun√ß√£o de resposta para o chatbot Gradio

    Args:
        message: Mensagem do usu√°rio
        chat_history: Hist√≥rico do chat (formato messages)
        selected_model: Modelo selecionado
        advanced_mode: Modo avan√ßado habilitado
        processing_enabled: Se o Processing Agent est√° habilitado
        processing_model: Modelo para o Processing Agent
        connection_type: Tipo de conex√£o ("csv" ou "postgresql")
        postgresql_config: Configura√ß√£o postgresql (se aplic√°vel)
        selected_table: Tabela selecionada (para postgresql)
        single_table_mode: Se deve usar apenas uma tabela (postgresql)
        top_k: N√∫mero m√°ximo de resultados (LIMIT) para queries SQL

    Returns:
        Tupla com (mensagem_vazia, hist√≥rico_atualizado, imagem_grafico)
    """
    import logging

    logging.info(f"[GRADIO RESPOND] ===== NOVA REQUISI√á√ÉO =====")
    logging.info(f"[GRADIO RESPOND] Message: {message}")
    logging.info(f"[GRADIO RESPOND] Selected model: {selected_model}")
    logging.info(f"[GRADIO RESPOND] Advanced mode: {advanced_mode}")
    logging.info(f"[GRADIO RESPOND] Processing enabled: {processing_enabled}")
    logging.info(f"[GRADIO RESPOND] Processing model: {processing_model}")
    logging.info(f"[GRADIO RESPOND] üìä TOP_K recebido: {top_k}")

    if not message.strip():
        return "", chat_history, None

    # Processa resposta
    response, graph_image_path, create_table_btn_update = chatbot_response(message, selected_model, advanced_mode, processing_enabled, processing_model, connection_type, postgresql_config, selected_table, single_table_mode, top_k)

    # Atualiza hist√≥rico no formato messages
    chat_history.append({"role": "user", "content": message})
    chat_history.append({"role": "assistant", "content": response})

    return "", chat_history, graph_image_path, create_table_btn_update

def handle_csv_and_clear_chat(file):
    """
    Processa csv e limpa chat com indicador de carregamento melhorado

    Args:
        file: Arquivo csv

    Returns:
        Tupla com (feedback, chat_limpo, grafico_limpo, status)
    """
    global connection_ready

    if file is None:
        connection_ready = False
        return "", [], gr.update(visible=False), "**Status**: <span class='status-error'>Nenhum arquivo selecionado</span>"

    # Indica carregamento
    connection_ready = False

    # Processa arquivo
    feedback = handle_csv_upload(file)

    # Status final baseado no resultado
    if "‚úÖ" in feedback:
        connection_ready = True
        final_status = "**Status**: <span class='status-connected'>csv processado com sucesso</span>"
    else:
        connection_ready = False
        final_status = "**Status**: <span class='status-error'>Erro no processamento do csv</span>"

    return feedback, [], gr.update(visible=False), final_status

def is_connection_ready(conn_type, pg_host=None, pg_port=None, pg_db=None, pg_user=None, pg_pass=None):
    """
    Verifica se h√° uma conex√£o de dados ativa e pronta para uso

    Args:
        conn_type: Tipo de conex√£o ("csv" ou "postgresql")
        pg_host, pg_port, pg_db, pg_user, pg_pass: Credenciais postgresql

    Returns:
        True se conex√£o est√° pronta, False caso contr√°rio
    """
    global connection_ready, chat_blocked
    return connection_ready and not chat_blocked

def show_loading_in_chat(message):
    """
    Mostra mensagem de carregamento apenas no chat

    Args:
        message: Mensagem de carregamento

    Returns:
        Hist√≥rico atualizado com mensagem de carregamento
    """
    global chat_blocked
    chat_blocked = True

    return [
        {"role": "user", "content": "Alterando tipo de conex√£o..."},
        {"role": "assistant", "content": f"üîÑ {message}"}
    ]

def clear_loading_from_chat():
    """
    Remove carregamento do chat
    """
    global chat_blocked
    chat_blocked = False

def load_default_csv_and_cleanup_postgresql():
    """
    Carrega a base csv padr√£o e limpa conex√µes postgresql ativas

    Returns:
        Mensagem de feedback sobre a opera√ß√£o
    """
    global connection_ready

    try:
        from agentgraph.utils.config import DEFAULT_CSV_PATH
        from agentgraph.utils.object_manager import get_object_manager
        import os

        # Verifica se o arquivo padr√£o existe
        if not os.path.exists(DEFAULT_CSV_PATH):
            connection_ready = False
            return "Arquivo csv padr√£o (tabela.csv) n√£o encontrado"

        # Limpa conex√µes postgresql ativas
        obj_manager = get_object_manager()

        # Fecha engines postgresql (SQLAlchemy engines t√™m m√©todo dispose)
        for engine_id, engine in obj_manager._engines.items():
            try:
                if hasattr(engine, 'dispose'):
                    engine.dispose()
                    logging.info(f"[CLEANUP] Engine postgresql {engine_id} fechada")
            except Exception as e:
                logging.warning(f"[CLEANUP] Erro ao fechar engine {engine_id}: {e}")

        # Limpa objetos postgresql do ObjectManager
        obj_manager.clear_all()
        logging.info("[CLEANUP] Objetos postgresql limpos do ObjectManager")

        # Carrega csv padr√£o atrav√©s do CustomNodeManager
        logging.info(f"[CSV_DEFAULT] Carregando arquivo padr√£o: {DEFAULT_CSV_PATH}")
        result = run_async(graph_manager.custom_node_manager.handle_csv_upload(DEFAULT_CSV_PATH, graph_manager.object_manager))

        # Atualiza sistema se carregamento foi bem-sucedido
        if result.get("success") and result.get("engine_id") and result.get("db_id"):
            graph_manager.engine_id = result["engine_id"]
            graph_manager.db_id = result["db_id"]

            # Cria novo agente SQL
            from agentgraph.agents.sql_agent import SQLAgentManager
            new_db = graph_manager.object_manager.get_database(graph_manager.db_id)
            if not new_db:
                logging.error(f"[CSV_DEFAULT] Banco de dados n√£o encontrado com ID: {graph_manager.db_id}")
                return "‚ùå Erro: Banco de dados n√£o encontrado ap√≥s carregamento padr√£o"

            top_k = graph_manager.object_manager.get_global_config('top_k', 10)
            new_sql_agent = SQLAgentManager(
                db=new_db,
                model_name="gpt-4o-mini",
                single_table_mode=False,
                selected_table=None,
                top_k=top_k
            )
            graph_manager.agent_id = graph_manager.object_manager.store_sql_agent(new_sql_agent, graph_manager.db_id)

            # Limpa cache
            cache_manager = graph_manager.object_manager.get_cache_manager(graph_manager.cache_id)
            if cache_manager:
                cache_manager.clear_cache()

            logging.info("[CSV_DEFAULT] Sistema atualizado com CSV padr√£o")

        if result.get("success", False):
            connection_ready = True
            return f"‚úÖ Base padr√£o carregada: {os.path.basename(DEFAULT_CSV_PATH)}"
        else:
            connection_ready = False
            return f"Erro ao carregar base padr√£o: {result.get('message', 'Erro desconhecido')}"

    except Exception as e:
        connection_ready = False
        error_msg = f"Erro ao carregar base padr√£o: {e}"
        logging.error(f"[CSV_DEFAULT] {error_msg}")
        return error_msg

def reset_all():
    """
    Reseta tudo e limpa interface

    Returns:
        Tupla com (feedback, chat_limpo, arquivo_limpo, grafico_limpo)
    """
    feedback = reset_system()
    return feedback, [], None, gr.update(visible=False)

# Fun√ß√µes globais para modal de cria√ß√£o de tabela
def show_create_table_modal():
    """Mostra o modal de cria√ß√£o de tabela"""
    logging.info("[CREATE_TABLE] üéØ Bot√£o de criar tabela clicado!")
    logging.info("[CREATE_TABLE] üéØ Abrindo modal...")
    return gr.update(visible=True), ""

def hide_create_table_modal():
    """Esconde o modal de cria√ß√£o de tabela"""
    logging.info("[CREATE_TABLE] ‚ùå Modal fechado")
    return gr.update(visible=False), ""

def create_table_from_sql(table_name, pg_host, pg_port, pg_db, pg_user, pg_pass):
    """Cria nova tabela no PostgreSQL baseada na SQL query"""
    global _last_sql_query

    try:
        from agentgraph.utils.postgresql_table_creator import create_table_from_query, validate_table_name

        if not table_name or not table_name.strip():
            return gr.update(visible=False), "‚ùå Nome da tabela √© obrigat√≥rio"

        # Valida nome da tabela
        if not validate_table_name(table_name.strip()):
            return gr.update(visible=False), "‚ùå Nome da tabela inv√°lido. Use apenas letras, n√∫meros e underscore, come√ßando com letra."

        # Recupera a SQL query do estado global
        if not _last_sql_query:
            return gr.update(visible=False), "‚ùå Nenhuma query SQL dispon√≠vel. Execute uma consulta primeiro."

        # Prepara configura√ß√£o PostgreSQL
        postgresql_config = {
            "host": pg_host,
            "port": pg_port,
            "database": pg_db,
            "username": pg_user,
            "password": pg_pass
        }

        # Cria a tabela (fun√ß√£o ass√≠ncrona executada de forma s√≠ncrona)
        result = run_async(create_table_from_query(
            table_name.strip(),
            _last_sql_query,
            postgresql_config
        ))

        return gr.update(visible=False), result["message"]

    except Exception as e:
        return gr.update(visible=False), f"‚ùå Erro ao criar tabela: {str(e)}"

# Interface Gradio
def create_interface():
    """Cria interface Gradio"""

    # CSS customizado para interface limpa e moderna
    custom_css = """
    .gradio-container {
        padding: 20px 30px !important;
    }

    /* Se√ß√µes de configura√ß√£o */
    .config-section {
        background: #f8f9fa;
        border-radius: 15px;
        padding: 0;
        margin: 16px 0;
        overflow: hidden;
    }

    /* Headers dos containers com espa√ßamento adequado */
    .gradio-container h3 {
        margin: 0 !important;
        color: #f1f3f4 !important;
        font-size: 16px !important;
        font-weight: 600 !important;
    }

    /* Espa√ßamento para status e informa√ß√µes nos containers */
    .config-section .status-connected,
    .config-section .status-loading,
    .config-section .status-error,
    .config-section .status-waiting {
        padding: 8px 20px !important;
        display: block !important;
    }

    .prose.svelte-lag733 {
        padding: 12px 20px !important;
        margin: 0 !important;
    }

    /* Conte√∫do dos containers */
    .config-content {
        padding: 20px;
    }

    /* Status indicators melhorados */
    .status-connected {
        color: #28a745;
        font-weight: 600;
        display: inline-flex;
        align-items: center;
        gap: 8px;
    }

    .status-loading {
        color: #ffc107;
        font-weight: 600;
        display: inline-flex;
        align-items: center;
        gap: 8px;
    }

    .status-loading::before {
        content: "‚è≥";
        animation: pulse 1.5s infinite;
    }

    .status-error {
        color: #dc3545;
        font-weight: 600;
        display: inline-flex;
        align-items: center;
        gap: 8px;
    }

    .status-waiting {
        color: #6c757d;
        font-weight: 500;
        display: inline-flex;
        align-items: center;
        gap: 8px;
    }

    /* Anima√ß√£o de carregamento */
    @keyframes pulse {
        0%, 100% { opacity: 1; }
        50% { opacity: 0.5; }
    }

    @keyframes spin {
        0% { transform: rotate(0deg); }
        100% { transform: rotate(360deg); }
    }

    /* Espa√ßamentos internos */
    .gr-form {
        padding: 16px;
    }

    .gr-box {
        padding: 16px;
        margin: 12px 0;
    }

    /* Melhorias para se√ß√£o postgresql */
    .pg-section {
        background: #f8f9fa;
        border-radius: 8px;
        padding: 16px;
        margin: 12px 0;
    }

    .pg-feedback {
        padding: 12px;
        margin: 8px 0;
        border-radius: 6px;
        background: #f1f3f4;
    }
    """

    with gr.Blocks(theme=gr.themes.Soft(), css=custom_css) as demo:

        with gr.Row():
            with gr.Column(scale=1):
                gr.Markdown("## Configura√ß√µes")

                # 1. CONEX√ÉO DE DADOS
                with gr.Group():
                    gr.Markdown("### Conex√£o de Dados")

                    with gr.Group():
                        connection_type = gr.Radio(
                            choices=[("CSV", "csv"), ("PostgreSQL", "postgresql")],
                            value="csv",
                            label="Tipo de Conex√£o"
                        )

                        # Status da conex√£o
                        connection_status = gr.Markdown("**Status**: <span class='status-connected'>Base padr√£o carregada</span>")

                # Se√ß√£o csv
                with gr.Group(visible=True) as csv_section:
                    csv_file = gr.File(
                        file_types=[".csv"],
                        label="Arquivo csv"
                    )
                    upload_feedback = gr.Markdown()

                # Se√ß√£o postgresql
                with gr.Group(visible=False) as postgresql_section:
                    with gr.Group():
                        with gr.Row():
                            # Host padr√£o baseado no ambiente
                            from agentgraph.utils.config import get_postgresql_host_for_environment
                            default_pg_host = get_postgresql_host_for_environment()

                            pg_host = gr.Textbox(
                                label="Host",
                                value=default_pg_host,
                                placeholder=default_pg_host,
                                scale=2
                            )
                            pg_port = gr.Textbox(
                                label="Porta",
                                value="5432",
                                placeholder="5432",
                                scale=1
                            )

                        pg_database = gr.Textbox(
                            label="Banco de Dados",
                            placeholder="nome_do_banco"
                        )

                        with gr.Row():
                            pg_username = gr.Textbox(
                                label="Usu√°rio",
                                placeholder="usuario",
                                scale=1
                            )
                            pg_password = gr.Textbox(
                                label="Senha",
                                type="password",
                                placeholder="senha",
                                scale=1
                            )

                        pg_connect_btn = gr.Button(
                            "Conectar postgresql",
                            variant="primary",
                            size="lg"
                        )

                        pg_feedback = gr.Markdown()

                    # Configura√ß√£o de tabelas (vis√≠vel ap√≥s conex√£o)
                    with gr.Group(visible=False) as pg_table_section:
                        gr.Markdown("#### Configura√ß√£o de Tabelas")

                        with gr.Group():
                            pg_single_table_mode = gr.Checkbox(
                                label="Modo Tabela √önica",
                                value=False
                            )

                            # Seletor de tabela
                            with gr.Group(visible=False) as pg_table_selector_group:
                                pg_table_selector = gr.Dropdown(
                                    choices=[],
                                    label="Selecionar Tabela",
                                    interactive=True
                                )

                            pg_table_info = gr.Markdown()

                # 2. CONFIGURA√á√ÉO DE MODELOS
                with gr.Group():
                    gr.Markdown("### Configura√ß√£o de Agentes")

                    with gr.Group():
                        # Processing Agent
                        processing_checkbox = gr.Checkbox(
                            label="Processing Agent",
                            value=False
                        )
                        processing_model_selector = gr.Dropdown(
                            choices=list(AVAILABLE_MODELS.keys()) + list(REFINEMENT_MODELS.keys()),
                            value="GPT-4o-mini",
                            label="Modelo do Processing Agent",
                            visible=False
                        )

                        # Modelo principal SQL
                        model_selector = gr.Dropdown(
                            list(AVAILABLE_MODELS.keys()),
                            value=DEFAULT_MODEL,
                            label="Modelo SQL Principal"
                        )

                # 3. CONFIGURA√á√ïES AVAN√áADAS
                with gr.Group():
                    gr.Markdown("### Configura√ß√µes Avan√ßadas")

                    with gr.Group():
                        advanced_checkbox = gr.Checkbox(
                            label="Refinar Resposta"
                        )

                        # Controle TOP_K para LIMIT das queries SQL
                        with gr.Group():
                            top_k_input = gr.Number(
                                value=DEFAULT_TOP_K,
                                label="LIMIT",
                                minimum=1,
                                maximum=100000,
                                step=1,
                                info="Define quantos registros ser√£o retornados nas consultas SQL"
                            )
                            top_k_apply_btn = gr.Button(
                                "Aplicar",
                                variant="primary",
                                scale=1
                            )
                            top_k_feedback = gr.Markdown("", visible=False)

                # 4. STATUS E CONTROLES
                with gr.Group():
                    gr.Markdown("### Status do Sistema")

                    with gr.Group():
                        # Status do LangSmith
                        if is_langsmith_enabled():
                            gr.Markdown(f"**LangSmith**: Ativo")
                        else:
                            gr.Markdown("**LangSmith**: Desabilitado")

                        reset_btn = gr.Button(
                            "Resetar Sistema",
                            variant="secondary"
                        )
                
            with gr.Column(scale=4):
                gr.Markdown("## Agent86")
                chatbot = gr.Chatbot(
                    height=600,
                    show_label=False,
                    container=True,
                    type="messages"
                )

                msg = gr.Textbox(placeholder="Digite sua pergunta aqui...", lines=1, label="")
                btn = gr.Button("Enviar", variant="primary")
                history_btn = gr.Button("Hist√≥rico", variant="secondary")
                history_output = gr.JSON()

                # Componente para exibir gr√°ficos - posicionado ap√≥s hist√≥rico
                graph_image = gr.Image(
                    label="üìä Visualiza√ß√£o de Dados",
                    visible=False,
                    height=500,  # Altura maior para ocupar mais espa√ßo
                    show_label=True,
                    container=True,
                    interactive=False,
                    show_download_button=True
                )

                # Bot√£o para criar tabela PostgreSQL (aparece quando dispon√≠vel)
                create_table_btn = gr.Button(
                    "üìä Criar Tabela no PostgreSQL",
                    visible=False,
                    variant="secondary",
                    size="sm"
                )

                # Modal para criar tabela PostgreSQL
                with gr.Group(visible=False) as create_table_modal:
                    gr.Markdown("### üìä Criar Nova Tabela no PostgreSQL")

                    with gr.Row():
                        table_name_input = gr.Textbox(
                            label="Nome da Tabela",
                            placeholder="Digite o nome da nova tabela...",
                            value="",
                            scale=3
                        )

                    with gr.Row():
                        gr.Markdown("**Aten√ß√£o:** A tabela ser√° criada com todos os dados da query (sem LIMIT).")

                    with gr.Row():
                        create_table_confirm_btn = gr.Button(
                            "‚úÖ Confirmar Cria√ß√£o",
                            variant="primary",
                            scale=1
                        )
                        create_table_cancel_btn = gr.Button(
                            "‚ùå Cancelar",
                            variant="secondary",
                            scale=1
                        )

                    create_table_status = gr.Markdown("", visible=False)

                download_file = gr.File(visible=False)



        # Fun√ß√£o para mostrar carregamento de transi√ß√£o no chat
        def show_transition_loading(conn_type):
            """Mostra carregamento de transi√ß√£o apenas no chat"""
            if conn_type == "csv":
                loading_chat = show_loading_in_chat("Fechando postgresql e carregando base csv padr√£o...")
                return "", loading_chat, gr.update(visible=False)
            else:
                return "", [], gr.update(visible=False)

        # Event handlers (usando as fun√ß√µes originais do sistema)
        def handle_response_with_graph(message, chat_history, model, advanced, processing_enabled, processing_model, conn_type, pg_host, pg_port, pg_db, pg_user, pg_pass, pg_table, pg_single_mode, top_k_value):
            """Wrapper para lidar com resposta e gr√°fico"""

            # Verifica se h√° conex√£o ativa antes de processar
            if not is_connection_ready(conn_type, pg_host, pg_port, pg_db, pg_user, pg_pass):
                error_msg = "‚ö†Ô∏è **Aguarde**: Configure e conecte a uma fonte de dados antes de fazer perguntas."
                chat_history.append({"role": "user", "content": message})
                chat_history.append({"role": "assistant", "content": error_msg})
                return "", chat_history, gr.update(visible=False)

            # Prepara configura√ß√£o postgresql se necess√°rio
            postgresql_config = None
            if conn_type == "postgresql":
                postgresql_config = {
                    "host": pg_host,
                    "port": pg_port,
                    "database": pg_db,
                    "username": pg_user,
                    "password": pg_pass
                }

            # Converte top_k_value para int se necess√°rio
            top_k = int(top_k_value) if top_k_value else 10
            empty_msg, updated_history, graph_path, create_table_btn_update = respond(message, chat_history, model, advanced, processing_enabled, processing_model, conn_type, postgresql_config, pg_table, pg_single_mode, top_k)

            # Controla visibilidade do componente de gr√°fico
            if graph_path:
                return empty_msg, updated_history, gr.update(value=graph_path, visible=True), create_table_btn_update
            else:
                return empty_msg, updated_history, gr.update(visible=False), create_table_btn_update

        def toggle_processing_agent(enabled):
            """Controla visibilidade do seletor de modelo do Processing Agent"""
            return gr.update(visible=enabled)

        def toggle_connection_type(conn_type):
            """Controla visibilidade das se√ß√µes de conex√£o - FECHA POSTGRES IMEDIATAMENTE"""
            global connection_ready

            if conn_type == "csv":
                # PRIMEIRO: Fecha container postgresql imediatamente
                # SEGUNDO: Executa transi√ß√£o em background
                feedback_msg = load_default_csv_and_cleanup_postgresql()
                if "‚úÖ" in feedback_msg:
                    connection_ready = True
                    status_msg = "**Status**: <span class='status-connected'>Base padr√£o carregada</span>"
                else:
                    connection_ready = False
                    status_msg = "**Status**: <span class='status-error'>Erro na conex√£o</span>"

                return (
                    gr.update(visible=True),   # csv_section - MOSTRA IMEDIATAMENTE
                    gr.update(visible=False),  # postgresql_section - FECHA IMEDIATAMENTE
                    feedback_msg,              # upload_feedback
                    status_msg,                # connection_status
                    # Limpa campos postgresql IMEDIATAMENTE
                    gr.update(value=""),       # pg_host
                    gr.update(value="5432"),   # pg_port
                    gr.update(value=""),       # pg_database
                    gr.update(value=""),       # pg_username
                    gr.update(value=""),       # pg_password
                    gr.update(value=""),       # pg_feedback
                    gr.update(visible=False),  # pg_table_section
                    gr.update(value=False),    # pg_single_table_mode
                    gr.update(visible=False),  # pg_table_selector_group
                    gr.update(choices=[], value=None),  # pg_table_selector
                    gr.update(value="")        # pg_table_info
                )

            else:  # postgresql
                connection_ready = False
                status_msg = "**Status**: <span class='status-waiting'>Aguardando configura√ß√£o postgresql</span>"
                return (
                    gr.update(visible=False),  # csv_section
                    gr.update(visible=True),   # postgresql_section
                    "",                        # upload_feedback
                    status_msg,                # connection_status
                    # Mant√©m campos postgresql como est√£o
                    gr.update(),  # pg_host
                    gr.update(),  # pg_port
                    gr.update(),  # pg_database
                    gr.update(),  # pg_username
                    gr.update(),  # pg_password
                    gr.update(),  # pg_feedback
                    gr.update(),  # pg_table_section
                    gr.update(),  # pg_single_table_mode
                    gr.update(),  # pg_table_selector_group
                    gr.update(),  # pg_table_selector
                    gr.update()   # pg_table_info
                )

        def handle_postgresql_connect(host, port, database, username, password):
            """Wrapper para conex√£o postgresql"""
            global connection_ready

            # Executa conex√£o
            connection_ready = False
            result = handle_postgresql_connection(host, port, database, username, password)

            # Se conex√£o foi bem-sucedida, retorna tabelas dispon√≠veis
            if "‚úÖ" in result:
                connection_ready = True
                try:
                    # Obt√©m tabelas do ObjectManager
                    from agentgraph.utils.object_manager import get_object_manager
                    obj_manager = get_object_manager()

                    # Busca metadados de conex√£o mais recente
                    all_metadata = obj_manager.get_all_connection_metadata()
                    if all_metadata:
                        latest_metadata = list(all_metadata.values())[-1]
                        tables = latest_metadata.get("tables", [])

                        # Status de sucesso
                        success_status = "**Status**: <span class='status-connected'>postgresql conectado com sucesso</span>"
                        table_info = f"**Modo Multi-Tabela ativo** - {len(tables)} tabelas dispon√≠veis"

                        # Retorna resultado + atualiza√ß√£o do seletor
                        return (
                            f"‚úÖ **Conectado com sucesso!** {len(tables)} tabelas encontradas",  # feedback
                            gr.update(visible=True),  # pg_table_section
                            False,  # pg_single_table_mode (padr√£o desativado)
                            gr.update(visible=False),  # pg_table_selector_group (oculto por padr√£o)
                            gr.update(choices=tables, value=tables[0] if tables else None),  # pg_table_selector
                            table_info,  # pg_table_info
                            success_status  # connection_status
                        )
                except Exception as e:
                    logging.error(f"Erro ao obter tabelas: {e}")

            # Se falhou, mant√©m se√ß√£o de tabela oculta
            connection_ready = False
            error_status = "**Status**: <span class='status-error'>Falha na conex√£o postgresql</span>"
            return (
                result,  # feedback
                gr.update(visible=False),  # pg_table_section
                False,  # pg_single_table_mode
                gr.update(visible=False),  # pg_table_selector_group
                gr.update(choices=[], value=None),  # pg_table_selector
                "",  # pg_table_info
                error_status  # connection_status
            )

        def toggle_table_mode(single_mode_enabled, current_table):
            """Alterna entre modo multi-tabela e tabela √∫nica"""
            if single_mode_enabled:
                # Modo tabela √∫nica ativado
                return (
                    gr.update(visible=True),  # pg_table_selector_group
                    f"**Modo Tabela √önica ativo** - Usando: {current_table or 'Selecione uma tabela'}"
                )
            else:
                # Modo multi-tabela ativado
                return (
                    gr.update(visible=False),  # pg_table_selector_group
                    "**Modo Multi-Tabela ativo** - Pode usar todas as tabelas e fazer JOINs"
                )

        # Configura√ß√£o de concorr√™ncia baseada no ambiente
        if is_docker_environment():
            # Docker: Alta concorr√™ncia sem fila
            concurrency_limit = None  # Sem limite
            logging.info("[GRADIO] Docker - Configurando alta concorr√™ncia sem limite")
        else:
            # Windows: Concorr√™ncia limitada para estabilidade
            concurrency_limit = 1
            logging.info("[GRADIO] Windows - Configurando concorr√™ncia limitada")

        msg.submit(
            handle_response_with_graph,
            inputs=[msg, chatbot, model_selector, advanced_checkbox, processing_checkbox, processing_model_selector, connection_type, pg_host, pg_port, pg_database, pg_username, pg_password, pg_table_selector, pg_single_table_mode, top_k_input],
            outputs=[msg, chatbot, graph_image, create_table_btn],
            show_progress=True,  # Mostra carregamento no input do chat
            concurrency_limit=concurrency_limit
        )

        btn.click(
            handle_response_with_graph,
            inputs=[msg, chatbot, model_selector, advanced_checkbox, processing_checkbox, processing_model_selector, connection_type, pg_host, pg_port, pg_database, pg_username, pg_password, pg_table_selector, pg_single_table_mode, top_k_input],
            outputs=[msg, chatbot, graph_image, create_table_btn],
            concurrency_limit=concurrency_limit
        )

        # Conecta bot√£o de aplicar TOP_K
        top_k_apply_btn.click(
            apply_top_k,
            inputs=[top_k_input],
            outputs=[top_k_feedback]
        ).then(
            lambda: gr.update(visible=True),
            outputs=[top_k_feedback]
        )

        csv_file.change(
            handle_csv_and_clear_chat,
            inputs=csv_file,
            outputs=[upload_feedback, chatbot, graph_image, connection_status],
            show_progress="minimal"  # Mostra carregamento m√≠nimo
        )

        reset_btn.click(
            reset_all,
            outputs=[upload_feedback, chatbot, csv_file, graph_image]
        )

        advanced_checkbox.change(
            toggle_advanced_mode,
            inputs=advanced_checkbox,
            outputs=[]
        )

        history_btn.click(
            toggle_history,
            outputs=history_output
        )

        processing_checkbox.change(
            toggle_processing_agent,
            inputs=processing_checkbox,
            outputs=processing_model_selector
        )

        # Executa toggle imediatamente (sem carregamento nos campos)
        connection_type.change(
            toggle_connection_type,
            inputs=connection_type,
            outputs=[
                csv_section, postgresql_section, upload_feedback, connection_status,
                pg_host, pg_port, pg_database, pg_username, pg_password, pg_feedback,
                pg_table_section, pg_single_table_mode, pg_table_selector_group,
                pg_table_selector, pg_table_info
            ],
            show_progress=False  # N√£o mostra carregamento nos campos
        )

        pg_connect_btn.click(
            handle_postgresql_connect,
            inputs=[pg_host, pg_port, pg_database, pg_username, pg_password],
            outputs=[pg_feedback, pg_table_section, pg_single_table_mode, pg_table_selector_group, pg_table_selector, pg_table_info, connection_status],
            show_progress="minimal"  # Mostra carregamento m√≠nimo
        )

        # Event handler para toggle de modo de tabela
        pg_single_table_mode.change(
            toggle_table_mode,
            inputs=[pg_single_table_mode, pg_table_selector],
            outputs=[pg_table_selector_group, pg_table_info]
        )

        # Event handler para bot√£o de criar tabela
        create_table_btn.click(
            show_create_table_modal,
            outputs=[create_table_modal, table_name_input]
        )

        # Event handlers para modal de cria√ß√£o de tabela
        create_table_cancel_btn.click(
            hide_create_table_modal,
            outputs=[create_table_modal, create_table_status]
        )

        create_table_confirm_btn.click(
            create_table_from_sql,
            inputs=[table_name_input, pg_host, pg_port, pg_database, pg_username, pg_password],
            outputs=[create_table_modal, create_table_status]
        )

    return demo

async def main():
    """Fun√ß√£o principal"""
    # Inicializa aplica√ß√£o
    success = await initialize_app()

    if not success:
        logging.error("Falha na inicializa√ß√£o. Encerrando aplica√ß√£o.")
        return

    # Cria e lan√ßa interface
    demo = create_interface()

    # Tenta diferentes portas se a padr√£o estiver ocupada
    ports_to_try = [GRADIO_PORT, 7861, 7862, 7863, 7864, 0]  # 0 = porta autom√°tica

    for port in ports_to_try:
        try:
            logging.info(f"Tentando iniciar interface Gradio na porta {port}")

            # Configura√ß√µes para Docker
            server_name = "0.0.0.0" if GRADIO_SHARE else "127.0.0.1"

            if GRADIO_SHARE:
                logging.info("üåê Configurando link p√∫blico do Gradio...")

            # Configura√ß√µes baseadas no ambiente
            if is_docker_environment():
                # Docker: Configura√ß√µes para alta concorr√™ncia
                max_threads = int(os.getenv("GRADIO_MAX_THREADS", "50"))
                logging.info(f"[GRADIO] Docker - Max threads: {max_threads}")

                demo.launch(
                    server_name=server_name,
                    server_port=port if port != 0 else None,
                    share=GRADIO_SHARE,
                    show_error=True,
                    quiet=False,
                    max_threads=max_threads
                )
            else:
                # Windows: Configura√ß√µes padr√£o
                logging.info(f"[GRADIO] Windows - Configura√ß√µes padr√£o")

                demo.launch(
                    server_name=server_name,
                    server_port=port if port != 0 else None,
                    share=GRADIO_SHARE,
                    show_error=True,
                    quiet=False
                )
            break  # Se chegou aqui, deu certo
        except OSError as e:
            if "Cannot find empty port" in str(e) and port != ports_to_try[-1]:
                logging.warning(f"Porta {port} ocupada, tentando pr√≥xima...")
                continue
            else:
                logging.error(f"Erro ao iniciar servidor: {e}")
                raise
        except Exception as e:
            logging.error(f"Erro inesperado ao iniciar interface: {e}")
            raise

if __name__ == "__main__":
    run_async(main())
