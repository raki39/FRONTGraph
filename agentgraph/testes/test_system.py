#!/usr/bin/env python3
"""
Script de teste do sistema de testes massivos
"""
import sys
import os
import asyncio
import logging

# Adiciona path do projeto
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

def test_imports():
    """Testa se todos os imports funcionam"""
    print("ğŸ” Testando imports...")
    
    try:
        from testes.test_runner import MassiveTestRunner
        print("  âœ… MassiveTestRunner")
        
        from testes.test_validator import TestValidator
        print("  âœ… TestValidator")
        
        from testes.report_generator import ReportGenerator
        print("  âœ… ReportGenerator")
        
        from utils.config import AVAILABLE_MODELS
        print("  âœ… AVAILABLE_MODELS")
        
        return True
    except Exception as e:
        print(f"  âŒ Erro no import: {e}")
        return False

def test_validator():
    """Testa o sistema de validaÃ§Ã£o"""
    print("\nğŸ” Testando validador...")
    
    try:
        from testes.test_validator import TestValidator
        
        validator = TestValidator()
        print("  âœ… Validator inicializado")
        
        # Teste de validaÃ§Ã£o por keyword
        result = validator._validate_with_keyword(
            "A resposta contÃ©m 150 usuÃ¡rios no total",
            "150 usuÃ¡rios"
        )
        
        if result['valid'] and result['score'] == 100:
            print("  âœ… ValidaÃ§Ã£o por keyword funcionando")
        else:
            print(f"  âŒ ValidaÃ§Ã£o por keyword falhou: {result}")
            return False
        
        # Teste de sintaxe SQL
        sql_result = validator.validate_sql_syntax("SELECT * FROM usuarios WHERE idade > 18")
        
        if sql_result['valid']:
            print("  âœ… ValidaÃ§Ã£o de sintaxe SQL funcionando")
        else:
            print(f"  âŒ ValidaÃ§Ã£o SQL falhou: {sql_result}")
            return False
        
        return True
    except Exception as e:
        print(f"  âŒ Erro no validator: {e}")
        return False

def test_report_generator():
    """Testa o gerador de relatÃ³rios"""
    print("\nğŸ” Testando gerador de relatÃ³rios...")
    
    try:
        from testes.report_generator import ReportGenerator
        
        generator = ReportGenerator()
        print("  âœ… ReportGenerator inicializado")
        
        # Dados de teste
        test_results = {
            'session_info': {
                'id': 'test_session',
                'question': 'Teste de pergunta',
                'validation_method': 'keyword'
            },
            'group_results': [
                {
                    'group_id': 1,
                    'group_config': {
                        'sql_model_name': 'GPT-4o-mini',
                        'processing_enabled': False,
                        'processing_model_name': None
                    },
                    'total_tests': 5,
                    'successful_tests': 4,
                    'valid_responses': 3,
                    'success_rate': 80.0,
                    'validation_rate': 60.0,
                    'response_consistency': 75.0,
                    'sql_consistency': 80.0,
                    'avg_execution_time': 5.2
                }
            ],
            'individual_results': [
                {
                    'group_id': 1,
                    'iteration': 1,
                    'sql_model': 'GPT-4o-mini',
                    'processing_enabled': False,
                    'success': True,
                    'validation': {'valid': True, 'score': 85}
                }
            ],
            'summary': {
                'total_groups': 1,
                'total_tests': 5,
                'overall_success_rate': 80.0,
                'overall_validation_rate': 60.0,
                'best_performing_group': {
                    'group_id': 1,
                    'group_config': {'sql_model_name': 'GPT-4o-mini'},
                    'validation_rate': 60.0
                },
                'most_consistent_group': {
                    'group_id': 1,
                    'group_config': {'sql_model_name': 'GPT-4o-mini'},
                    'response_consistency': 75.0
                }
            }
        }
        
        # Testa criaÃ§Ã£o de DataFrames
        group_df = generator._create_group_summary_dataframe(test_results)
        individual_df = generator._create_individual_results_dataframe(test_results)
        general_df = generator._create_general_summary_dataframe(test_results)
        
        if len(group_df) > 0 and len(individual_df) > 0 and len(general_df) > 0:
            print("  âœ… DataFrames criados com sucesso")
        else:
            print("  âŒ Erro na criaÃ§Ã£o de DataFrames")
            return False
        
        return True
    except Exception as e:
        print(f"  âŒ Erro no report generator: {e}")
        return False

async def test_runner_basic():
    """Testa funcionalidades bÃ¡sicas do runner"""
    print("\nğŸ” Testando runner bÃ¡sico...")
    
    try:
        from testes.test_runner import MassiveTestRunner
        
        runner = MassiveTestRunner(max_workers=2)
        print("  âœ… MassiveTestRunner inicializado")
        
        # Testa cÃ¡lculo de consistÃªncia
        items = ["resposta A", "resposta A", "resposta B", "resposta A"]
        consistency = runner._calculate_consistency(items)
        
        expected = 3/4  # 3 "resposta A" de 4 total
        if abs(consistency - expected) < 0.01:
            print("  âœ… CÃ¡lculo de consistÃªncia funcionando")
        else:
            print(f"  âŒ ConsistÃªncia incorreta: esperado {expected}, obtido {consistency}")
            return False
        
        # Testa status
        status = runner.get_status()
        if 'current_status' in status and status['current_status'] == 'idle':
            print("  âœ… Status funcionando")
        else:
            print(f"  âŒ Status incorreto: {status}")
            return False
        
        return True
    except Exception as e:
        print(f"  âŒ Erro no runner: {e}")
        return False

def test_flask_app():
    """Testa se o app Flask pode ser importado"""
    print("\nğŸ” Testando Flask app...")
    
    try:
        from testes.app_teste import app
        print("  âœ… Flask app importado")
        
        # Testa se as rotas estÃ£o definidas
        routes = [rule.rule for rule in app.url_map.iter_rules()]
        expected_routes = ['/', '/api/models', '/api/create_test_session']
        
        for route in expected_routes:
            if route in routes:
                print(f"  âœ… Rota {route} definida")
            else:
                print(f"  âŒ Rota {route} nÃ£o encontrada")
                return False
        
        return True
    except Exception as e:
        print(f"  âŒ Erro no Flask app: {e}")
        return False

def test_agentgraph_integration():
    """Testa integraÃ§Ã£o com AgentGraph"""
    print("\nğŸ” Testando integraÃ§Ã£o com AgentGraph...")
    
    try:
        from utils.config import AVAILABLE_MODELS, validate_config
        
        # Testa se modelos estÃ£o disponÃ­veis
        if len(AVAILABLE_MODELS) > 0:
            print(f"  âœ… {len(AVAILABLE_MODELS)} modelos disponÃ­veis")
        else:
            print("  âŒ Nenhum modelo disponÃ­vel")
            return False
        
        # Testa validaÃ§Ã£o de config (pode falhar se APIs nÃ£o configuradas)
        try:
            validate_config()
            print("  âœ… ConfiguraÃ§Ã£o vÃ¡lida")
        except Exception as e:
            print(f"  âš ï¸ ConfiguraÃ§Ã£o incompleta: {e}")
            print("  ğŸ’¡ Configure as APIs no .env para funcionalidade completa")
        
        return True
    except Exception as e:
        print(f"  âŒ Erro na integraÃ§Ã£o: {e}")
        return False

async def main():
    """FunÃ§Ã£o principal de teste"""
    print("ğŸ§ª TESTE DO SISTEMA DE TESTES MASSIVOS")
    print("=" * 50)
    
    tests = [
        ("Imports", test_imports),
        ("Validator", test_validator),
        ("Report Generator", test_report_generator),
        ("Runner BÃ¡sico", test_runner_basic),
        ("Flask App", test_flask_app),
        ("IntegraÃ§Ã£o AgentGraph", test_agentgraph_integration)
    ]
    
    passed = 0
    total = len(tests)
    
    for test_name, test_func in tests:
        print(f"\nğŸ“‹ {test_name}")
        print("-" * 30)
        
        try:
            if asyncio.iscoroutinefunction(test_func):
                result = await test_func()
            else:
                result = test_func()
            
            if result:
                passed += 1
                print(f"âœ… {test_name} PASSOU")
            else:
                print(f"âŒ {test_name} FALHOU")
        except Exception as e:
            print(f"âŒ {test_name} ERRO: {e}")
    
    print("\n" + "=" * 50)
    print(f"ğŸ“Š RESULTADO FINAL: {passed}/{total} testes passaram")
    
    if passed == total:
        print("ğŸ‰ TODOS OS TESTES PASSARAM!")
        print("ğŸš€ Sistema pronto para uso!")
        print("ğŸ’¡ Execute: python testes/run_tests.py")
    else:
        print("âš ï¸ Alguns testes falharam")
        print("ğŸ”§ Verifique os erros acima")
    
    print("=" * 50)
    
    return passed == total

if __name__ == '__main__':
    success = asyncio.run(main())
    sys.exit(0 if success else 1)
