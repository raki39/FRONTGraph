#!/usr/bin/env python3
"""
Teste rÃ¡pido da validaÃ§Ã£o melhorada
"""

import asyncio
import json
from agentgraph.agents.validation_agent import ValidationAgentManager

async def test_individual_validation():
    """Testa validaÃ§Ã£o individual"""
    print("\n" + "="*80)
    print("TESTE 1: VALIDAÃ‡ÃƒO INDIVIDUAL")
    print("="*80)
    
    agent = ValidationAgentManager(model="gpt-4o-mini")
    
    question = "Qual foi o Ãºltimo mÃªs de vendas?"
    sql_query = "SELECT SUM(amount) FROM sales WHERE MONTH(date) = MONTH(NOW())"
    response = "O total foi R$ 50.000"
    
    print(f"\nğŸ“ Pergunta: {question}")
    print(f"ğŸ” Query: {sql_query}")
    print(f"ğŸ“Š Resposta: {response}")
    
    result = await agent.validate_individual(question, sql_query, response, auto_improve=True)
    
    print("\nâœ… Resultado da ValidaÃ§Ã£o Individual:")
    print(json.dumps(result, indent=2, ensure_ascii=False))
    
    return result

async def test_comparative_validation():
    """Testa validaÃ§Ã£o comparativa"""
    print("\n" + "="*80)
    print("TESTE 2: VALIDAÃ‡ÃƒO COMPARATIVA")
    print("="*80)
    
    agent = ValidationAgentManager(model="gpt-4o-mini")
    
    current_run = {
        "question": "Qual foi o Ãºltimo mÃªs de vendas?",
        "sql_query": "SELECT SUM(amount) FROM sales WHERE MONTH(date) = MONTH(NOW())",
        "response": "O total foi R$ 50.000"
    }
    
    compared_runs = [
        {
            "run_id": 1,
            "question": "Qual foi o mÃªs passado de vendas?",
            "sql_query": "SELECT SUM(amount) FROM sales WHERE MONTH(date) = MONTH(NOW() - INTERVAL 1 MONTH)",
            "response": "O total foi R$ 45.000"
        },
        {
            "run_id": 2,
            "question": "Qual foi o total de vendas recentemente?",
            "sql_query": "SELECT SUM(amount) FROM sales WHERE date >= NOW() - INTERVAL 30 DAY",
            "response": "O total foi R$ 52.000"
        }
    ]
    
    print(f"\nğŸ“ Pergunta Atual: {current_run['question']}")
    print(f"ğŸ“ Perguntas para ComparaÃ§Ã£o:")
    for run in compared_runs:
        print(f"   - {run['question']}")
    
    result = await agent.validate_comparative(current_run, compared_runs)
    
    print("\nâœ… Resultado da ValidaÃ§Ã£o Comparativa:")
    print(json.dumps(result, indent=2, ensure_ascii=False))
    
    return result

async def main():
    """Executa testes"""
    print("\nğŸš€ Iniciando testes de validaÃ§Ã£o melhorada...")
    
    try:
        individual_result = await test_individual_validation()
        comparative_result = await test_comparative_validation()
        
        print("\n" + "="*80)
        print("âœ… TESTES CONCLUÃDOS COM SUCESSO!")
        print("="*80)
        
        # Verificar se os campos esperados estÃ£o presentes
        print("\nğŸ“‹ VerificaÃ§Ã£o de Campos:")
        
        print("\nValidaÃ§Ã£o Individual:")
        for field in ["question_clarity_score", "query_correctness_score", "response_accuracy_score", 
                      "overall_score", "issues_found", "observations", "suggestions", "improved_question"]:
            present = field in individual_result
            print(f"  {'âœ“' if present else 'âœ—'} {field}")
        
        print("\nValidaÃ§Ã£o Comparativa:")
        for field in ["consistency_score", "inconsistencies_found", "observations", "suggestions", "improved_question"]:
            present = field in comparative_result
            print(f"  {'âœ“' if present else 'âœ—'} {field}")
            
    except Exception as e:
        print(f"\nâŒ Erro durante os testes: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    asyncio.run(main())

