#!/usr/bin/env python3
"""
Teste end-to-end dos endpoints de validaÃ§Ã£o
Testa os endpoints de validaÃ§Ã£o via API real
"""

import requests
import json
import time
import logging
from typing import Dict, Any, Optional

# ConfiguraÃ§Ã£o de logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class ValidationEndpointsTest:
    def __init__(self, base_url: str = "http://localhost:8000"):
        self.base_url = base_url
        self.token = None
        self.user_id = None
        self.agent_id = None
        self.connection_id = None
        self.run_ids = []  # Para armazenar IDs das runs criadas

    def register_user(self, nome: str = "Teste", email: str = "tiraramos@hotmail.com", password: str = "tiago111") -> bool:
        """Registra um novo usuÃ¡rio para teste"""
        try:
            logger.info(f"ğŸ“ Registrando usuÃ¡rio: {email}...")

            response = requests.post(f"{self.base_url}/auth/register", json={
                "nome": nome,
                "email": email,
                "password": password
            })

            if response.status_code == 200:
                user_data = response.json()
                logger.info(f"âœ… UsuÃ¡rio registrado! ID: {user_data['id']}")
                return True
            elif response.status_code == 400 and "jÃ¡ cadastrado" in response.text:
                logger.info(f"â„¹ï¸ UsuÃ¡rio jÃ¡ existe, continuando...")
                return True
            else:
                logger.error(f"âŒ Erro no registro: {response.status_code} - {response.text}")
                return False

        except Exception as e:
            logger.error(f"âŒ Erro no registro: {e}")
            return False

    def login(self, email: str = "teste@validacao.com", password: str = "teste123") -> bool:
        """Faz login e obtÃ©m token"""
        try:
            logger.info(f"ğŸ” Fazendo login com {email}...")

            response = requests.post(f"{self.base_url}/auth/login", data={
                "username": email,
                "password": password
            })

            if response.status_code == 200:
                data = response.json()
                self.token = data["access_token"]
                self.user_id = data["user"]["id"]
                logger.info(f"âœ… Login realizado! User ID: {self.user_id}")
                return True
            else:
                logger.error(f"âŒ Erro no login: {response.status_code} - {response.text}")
                return False

        except Exception as e:
            logger.error(f"âŒ Erro no login: {e}")
            return False

    def get_headers(self) -> Dict[str, str]:
        """Retorna headers com token de autenticaÃ§Ã£o"""
        return {
            "Authorization": f"Bearer {self.token}",
            "Content-Type": "application/json"
        }

    def create_test_dataset(self) -> int:
        """Cria um dataset de teste"""
        try:
            logger.info("ğŸ“Š Criando dataset de teste...")

            # Criar um CSV simples em memÃ³ria
            csv_content = """id,nome,categoria,preco,estoque
1,Produto A,EletrÃ´nicos,100.50,50
2,Produto B,Roupas,25.99,30
3,Produto C,Casa,75.00,20
4,Produto D,EletrÃ´nicos,200.00,15
5,Produto E,Roupas,45.50,40"""

            # Simular upload de arquivo
            files = {
                'file': ('test_data.csv', csv_content, 'text/csv')
            }

            response = requests.post(
                f"{self.base_url}/datasets/upload",
                headers={"Authorization": f"Bearer {self.token}"},  # Sem Content-Type para multipart
                files=files
            )

            if response.status_code == 200:
                dataset_data = response.json()
                dataset_id = dataset_data["id"]
                logger.info(f"âœ… Dataset criado! ID: {dataset_id}")
                return dataset_id
            else:
                logger.error(f"âŒ Erro ao criar dataset: {response.status_code} - {response.text}")
                return None

        except Exception as e:
            logger.error(f"âŒ Erro ao criar dataset: {e}")
            return None

    def create_csv_connection(self, dataset_id: int) -> bool:
        """Cria conexÃ£o SQLite para teste"""
        try:
            logger.info("ğŸ”— Criando conexÃ£o SQLite para teste...")

            response = requests.post(f"{self.base_url}/connections/",
                headers=self.get_headers(),
                json={
                    "tipo": "sqlite",
                    "dataset_id": dataset_id
                }
            )

            if response.status_code == 200:
                connection_data = response.json()
                self.connection_id = connection_data["id"]
                logger.info(f"âœ… ConexÃ£o SQLite criada! ID: {self.connection_id}")
                return True
            else:
                logger.error(f"âŒ Erro ao criar conexÃ£o: {response.status_code} - {response.text}")
                return False

        except Exception as e:
            logger.error(f"âŒ Erro ao criar conexÃ£o SQLite: {e}")
            return False

    def create_test_agent(self) -> bool:
        """Cria agente para teste de validaÃ§Ã£o"""
        try:
            logger.info("ğŸ¤– Criando agente para teste de validaÃ§Ã£o...")

            response = requests.post(f"{self.base_url}/agents/",
                headers=self.get_headers(),
                json={
                    "nome": "Agente Teste ValidaÃ§Ã£o",
                    "connection_id": self.connection_id,
                    "selected_model": "gpt-4o-mini",
                    "top_k": 5,
                    "include_tables_key": "*",
                    "advanced_mode": False,
                    "processing_enabled": True,
                    "refinement_enabled": False,
                    "single_table_mode": False,
                    "selected_table": None
                }
            )

            if response.status_code == 200:
                agent_data = response.json()
                self.agent_id = agent_data["id"]
                logger.info(f"âœ… Agente criado! ID: {self.agent_id} - {agent_data['nome']}")
                return True
            else:
                logger.error(f"âŒ Erro ao criar agente: {response.status_code} - {response.text}")
                return False

        except Exception as e:
            logger.error(f"âŒ Erro ao criar agente: {e}")
            return False

    def send_question(self, question: str) -> Dict[str, Any]:
        """Envia pergunta para o agente e aguarda conclusÃ£o"""
        try:
            logger.info(f"ğŸ’¬ Enviando pergunta: '{question}'")

            # Enviar pergunta
            response = requests.post(
                f"{self.base_url}/agents/{self.agent_id}/run",
                headers=self.get_headers(),
                json={"question": question}
            )

            if response.status_code == 200:
                run_data = response.json()
                run_id = run_data['id']
                logger.info(f"âœ… Pergunta enviada! Run ID: {run_id}")

                # Aguardar conclusÃ£o
                logger.info(f"â³ Aguardando conclusÃ£o da execuÃ§Ã£o {run_id}...")

                max_wait = 60  # 1 minuto
                start_time = time.time()

                while time.time() - start_time < max_wait:
                    check_response = requests.get(
                        f"{self.base_url}/runs/{run_id}",
                        headers=self.get_headers()
                    )

                    if check_response.status_code == 200:
                        run_status = check_response.json()
                        status = run_status.get("status", "unknown")

                        if status in ["success", "failure"]:
                            logger.info(f"âœ… ExecuÃ§Ã£o concluÃ­da com status: {status}")

                            # Verificar se tem dados necessÃ¡rios para validaÃ§Ã£o
                            sql_used = run_status.get('sql_used')
                            result_data = run_status.get('result_data')

                            logger.info(f"ğŸ“Š SQL usado: {'âœ…' if sql_used else 'âŒ'}")
                            logger.info(f"ğŸ“Š Resultado: {'âœ…' if result_data else 'âŒ'}")

                            # Mostrar todos os campos da run para debug
                            logger.info(f"ğŸ” Campos da run: {list(run_status.keys())}")

                            if sql_used:
                                logger.info(f"ğŸ” SQL: {sql_used[:100]}...")
                            if result_data:
                                logger.info(f"ğŸ” Resultado: {result_data[:100]}...")

                            # Verificar se tem SQL em outros campos
                            for key, value in run_status.items():
                                if 'sql' in key.lower() and value:
                                    logger.info(f"ğŸ” Campo {key}: {str(value)[:100]}...")

                            self.run_ids.append(run_id)
                            return run_status
                        else:
                            logger.info(f"ğŸ”„ Status atual: {status}")
                            time.sleep(3)
                    else:
                        logger.error(f"âŒ Erro ao consultar run: {check_response.status_code}")
                        time.sleep(3)

                logger.error(f"â° Timeout aguardando conclusÃ£o da execuÃ§Ã£o")
                return {}
            else:
                logger.error(f"âŒ Erro ao enviar pergunta: {response.status_code} - {response.text}")
                return {}

        except Exception as e:
            logger.error(f"âŒ Erro ao enviar pergunta: {e}")
            return {}

    def test_validation_individual_detailed(self, run_id: int, query_name: str) -> bool:
        """
        Testa validaÃ§Ã£o individual de uma run com anÃ¡lise detalhada dos resultados
        """
        try:
            logger.info(f"ğŸ” TESTE: ValidaÃ§Ã£o Individual - Run {run_id} ({query_name} query)")
            logger.info("-" * 50)
            logger.info("ğŸ“ Enviando request de validaÃ§Ã£o individual...")

            validation_request = {
                "validation_type": "individual",
                "validation_model": "gpt-4o-mini",
                "auto_improve_question": True,
                "comparison_limit": 3,
                "use_similarity": True
            }

            logger.info(f"ğŸ“ Enviando request de validaÃ§Ã£o individual...")
            response = requests.post(
                f"{self.base_url}/validation/runs/{run_id}/validate",
                headers=self.get_headers(),
                json=validation_request
            )

            logger.info(f"ğŸ“Š Status Code: {response.status_code}")

            if response.status_code == 200:
                result = response.json()
                logger.info(f"ğŸ“Š ValidaÃ§Ã£o individual executada:")
                logger.info(f"   Run ID: {result['run_id']}")
                logger.info(f"   Tipo: {result['validation_type']}")
                logger.info(f"   Sucesso: {result['validation_success']}")
                logger.info(f"   Tempo: {result['validation_time']:.2f}s")

                # Verificar se houve erro
                if result.get('validation_error'):
                    # Se o erro Ã© por falta de SQL, Ã© comportamento esperado
                    if "nÃ£o possui SQL" in result['validation_error']:
                        logger.warning(f"   âš ï¸ ValidaÃ§Ã£o pulada (sem SQL): {result['validation_error']}")
                        return True  # Aceitar como sucesso
                    else:
                        logger.error(f"   âŒ Erro: {result['validation_error']}")
                        return False

                # Verificar se a validaÃ§Ã£o foi bem-sucedida
                if not result['validation_success']:
                    logger.error(f"   âŒ ValidaÃ§Ã£o falhou sem resultado")
                    return False

                if result.get('validation_result'):
                    validation_result = result['validation_result']
                    logger.info(f"   âœ… Score geral: {validation_result.get('overall_score', 'N/A')}")
                    logger.info(f"   âœ… Issues: {len(validation_result.get('issues_found', []))}")
                    logger.info(f"   âœ… SugestÃµes: {len(validation_result.get('suggestions', []))}")

                    # ğŸ“Š ANÃLISE DETALHADA DOS RESULTADOS
                    logger.info("\n   ğŸ“Š ANÃLISE DETALHADA:")
                    logger.info(f"   â”œâ”€ Score Geral: {validation_result.get('overall_score', 'N/A')}")
                    logger.info(f"   â”œâ”€ Score Clareza: {validation_result.get('question_clarity_score', 'N/A')}")
                    logger.info(f"   â”œâ”€ Score CorreÃ§Ã£o: {validation_result.get('query_correctness_score', 'N/A')}")
                    logger.info(f"   â””â”€ Score PrecisÃ£o: {validation_result.get('response_accuracy_score', 'N/A')}")

                    # ğŸ” ISSUES ENCONTRADOS
                    issues = validation_result.get('issues_found', [])
                    if issues:
                        logger.info(f"\n   ğŸ” ISSUES ENCONTRADOS ({len(issues)}):")
                        for i, issue in enumerate(issues, 1):
                            logger.info(f"   {i}. {issue}")
                    else:
                        logger.info("\n   âœ… Nenhum issue encontrado")

                    # ğŸ’¡ SUGESTÃ•ES DE MELHORIA
                    suggestions = validation_result.get('suggestions', [])
                    if suggestions:
                        logger.info(f"\n   ğŸ’¡ SUGESTÃ•ES DE MELHORIA ({len(suggestions)}):")
                        for i, suggestion in enumerate(suggestions, 1):
                            logger.info(f"   {i}. {suggestion}")
                    else:
                        logger.info("\n   âœ… Nenhuma sugestÃ£o adicional")

                    # ğŸ¯ PERGUNTA MELHORADA
                    improved = validation_result.get('improved_question')
                    if improved:
                        logger.info(f"\n   ğŸ¯ PERGUNTA MELHORADA:")
                        logger.info(f"   '{improved}'")

                    # âœ… VERIFICAÃ‡ÃƒO DE SUCESSO
                    if validation_result.get('overall_score') is not None:
                        score = validation_result.get('overall_score')
                        if score >= 0.8:
                            logger.info(f"\n   âœ… VALIDAÃ‡ÃƒO EXCELENTE! Score: {score}")
                        elif score >= 0.6:
                            logger.info(f"\n   âš ï¸ VALIDAÃ‡ÃƒO BOA com melhorias. Score: {score}")
                        else:
                            logger.info(f"\n   âŒ VALIDAÃ‡ÃƒO PRECISA MELHORIAS. Score: {score}")

                        logger.info(f"   ğŸ“ˆ Resumo: {len(issues)} issues, {len(suggestions)} sugestÃµes")
                        return True
                    else:
                        logger.error("   âŒ ValidaÃ§Ã£o nÃ£o retornou score vÃ¡lido")
                        return False
                else:
                    logger.error("   âŒ ValidaÃ§Ã£o nÃ£o retornou resultado")
                    return False
            else:
                logger.error(f"âŒ Erro na validaÃ§Ã£o individual: {response.status_code} - {response.text}")
                return False

        except Exception as e:
            logger.error(f"âŒ Erro no teste de validaÃ§Ã£o individual: {e}")
            return False

    def test_validation_comparative_detailed(self, run_id: int) -> bool:
        """
        Testa validaÃ§Ã£o comparativa com anÃ¡lise detalhada das inconsistÃªncias
        """
        try:
            logger.info(f"ğŸ” TESTE: ValidaÃ§Ã£o Comparativa - Run {run_id}")
            logger.info("-" * 50)
            logger.info("ğŸ“ Enviando request de validaÃ§Ã£o comparativa...")

            validation_request = {
                "validation_type": "comparative",
                "validation_model": "gpt-4o-mini",
                "auto_improve_question": False,
                "comparison_limit": 3,
                "use_similarity": True
            }

            logger.info(f"ğŸ“ Enviando request de validaÃ§Ã£o comparativa...")
            response = requests.post(
                f"{self.base_url}/validation/runs/{run_id}/validate",
                headers=self.get_headers(),
                json=validation_request
            )

            logger.info(f"ğŸ“Š Status Code: {response.status_code}")

            if response.status_code == 200:
                result = response.json()
                logger.info(f"ğŸ“Š ValidaÃ§Ã£o comparativa executada:")
                logger.info(f"   Run ID: {result['run_id']}")
                logger.info(f"   Tipo: {result['validation_type']}")
                logger.info(f"   Sucesso: {result['validation_success']}")
                logger.info(f"   Tempo: {result['validation_time']:.2f}s")

                # ğŸ” ANÃLISE DO RESULTADO COMPARATIVO
                if result.get('validation_error'):
                    if "Nenhuma run fornecida para comparaÃ§Ã£o" in result['validation_error']:
                        logger.warning(f"   âš ï¸ Sem runs para comparar: {result['validation_error']}")
                        logger.info("   â„¹ï¸ Isso Ã© esperado se nÃ£o hÃ¡ runs similares anteriores")
                        return True
                    else:
                        logger.error(f"   âŒ Erro inesperado: {result['validation_error']}")
                        return False

                if result.get('validation_result'):
                    validation_result = result['validation_result']

                    # ğŸ“Š ANÃLISE DETALHADA DA COMPARAÃ‡ÃƒO
                    logger.info("\n   ğŸ“Š ANÃLISE COMPARATIVA DETALHADA:")
                    logger.info(f"   â”œâ”€ Score ConsistÃªncia: {validation_result.get('consistency_score', 'N/A')}")

                    compared_ids = validation_result.get('compared_run_ids', [])
                    logger.info(f"   â”œâ”€ Runs Comparadas: {len(compared_ids)} runs")
                    if compared_ids:
                        logger.info(f"   â”‚  â””â”€ IDs: {compared_ids}")

                    # ğŸ” INCONSISTÃŠNCIAS DETECTADAS
                    inconsistencies = validation_result.get('inconsistencies_found', [])
                    logger.info(f"   â””â”€ InconsistÃªncias: {len(inconsistencies)} encontradas")

                    if inconsistencies:
                        logger.info(f"\n   âš ï¸ INCONSISTÃŠNCIAS DETECTADAS ({len(inconsistencies)}):")
                        for i, inconsistency in enumerate(inconsistencies, 1):
                            logger.info(f"   {i}. {inconsistency}")
                    else:
                        logger.info("\n   âœ… Nenhuma inconsistÃªncia detectada")

                    # âœ… VERIFICAÃ‡ÃƒO DE SUCESSO
                    consistency_score = validation_result.get('consistency_score')
                    if consistency_score is not None:
                        if consistency_score >= 0.8:
                            logger.info(f"\n   âœ… ALTA CONSISTÃŠNCIA! Score: {consistency_score}")
                        elif consistency_score >= 0.6:
                            logger.info(f"\n   âš ï¸ CONSISTÃŠNCIA MODERADA. Score: {consistency_score}")
                        else:
                            logger.info(f"\n   âŒ BAIXA CONSISTÃŠNCIA. Score: {consistency_score}")

                    logger.info(f"   ğŸ“ˆ Resumo: {len(compared_ids)} comparaÃ§Ãµes, {len(inconsistencies)} inconsistÃªncias")
                    logger.info("   âœ… ValidaÃ§Ã£o comparativa funcionou corretamente!")
                    return True
                else:
                    logger.info("   â„¹ï¸ ValidaÃ§Ã£o comparativa sem resultado (comportamento esperado)")
                    return True
            else:
                logger.error(f"âŒ Erro na validaÃ§Ã£o comparativa: {response.status_code} - {response.text}")
                return False

        except Exception as e:
            logger.error(f"âŒ Erro no teste de validaÃ§Ã£o comparativa: {e}")
            return False

    def test_list_validations_detailed(self, run_id: int, query_name: str) -> bool:
        """
        Lista validaÃ§Ãµes de uma run com anÃ¡lise detalhada dos dados salvos
        """
        try:
            logger.info(f"ğŸ” TESTE: Listar ValidaÃ§Ãµes - Run {run_id} ({query_name} query)")
            logger.info("-" * 50)

            logger.info(f"ğŸ“ Buscando validaÃ§Ãµes da run {run_id}...")
            response = requests.get(
                f"{self.base_url}/validation/runs/{run_id}/validations",
                headers=self.get_headers()
            )

            logger.info(f"ğŸ“Š Status Code: {response.status_code}")

            if response.status_code == 200:
                validations = response.json()
                logger.info(f"âœ… Encontradas {len(validations)} validaÃ§Ãµes salvas:")

                if validations:
                    logger.info("\n   ğŸ“‹ VALIDAÃ‡Ã•ES ENCONTRADAS:")
                    for i, validation in enumerate(validations, 1):
                        logger.info(f"   {i}. â”Œâ”€ Tipo: {validation['validation_type']}")
                        logger.info(f"      â”œâ”€ Sucesso: {validation['validation_success']}")
                        logger.info(f"      â”œâ”€ Tempo: {validation['validation_time']:.2f}s")
                        logger.info(f"      â”œâ”€ Criado: {validation['created_at']}")

                        if validation.get('validation_result'):
                            result = validation['validation_result']
                            logger.info(f"      â”œâ”€ Score: {result.get('overall_score', 'N/A')}")
                            logger.info(f"      â”œâ”€ Issues: {len(result.get('issues_found', []))}")
                            logger.info(f"      â””â”€ SugestÃµes: {len(result.get('suggestions', []))}")
                        else:
                            logger.info(f"      â””â”€ Sem resultado detalhado")

                    logger.info(f"\n   âœ… PERSISTÃŠNCIA FUNCIONANDO! {len(validations)} validaÃ§Ã£o(Ãµes) salva(s)")
                    return True
                else:
                    logger.warning("   âš ï¸ Nenhuma validaÃ§Ã£o encontrada (pode ser problema de timing)")
                    return True  # NÃ£o falhar por isso
            else:
                logger.error(f"âŒ Erro ao listar validaÃ§Ãµes: {response.text}")
                return False

        except Exception as e:
            logger.error(f"âŒ Erro no teste de listagem: {e}")
            return False

    def test_validation_stats_detailed(self) -> bool:
        """
        Testa estatÃ­sticas de validaÃ§Ã£o com anÃ¡lise detalhada dos dados agregados
        """
        try:
            logger.info(f"ğŸ” TESTE: EstatÃ­sticas Agregadas de ValidaÃ§Ã£o")
            logger.info("-" * 50)

            logger.info(f"ğŸ“ Buscando estatÃ­sticas consolidadas do usuÃ¡rio...")
            response = requests.get(
                f"{self.base_url}/validation/validations/stats",
                headers=self.get_headers()
            )

            logger.info(f"ğŸ“Š Status Code: {response.status_code}")

            if response.status_code == 200:
                stats = response.json()

                # ğŸ“Š ANÃLISE DETALHADA DAS ESTATÃSTICAS
                logger.info("\n   ğŸ“Š ESTATÃSTICAS CONSOLIDADAS:")
                logger.info(f"   â”œâ”€ Total de ValidaÃ§Ãµes: {stats['total_validations']}")
                logger.info(f"   â”œâ”€ ValidaÃ§Ãµes Bem-sucedidas: {stats['successful_validations']}")

                success_rate = stats['success_rate']
                if success_rate >= 80:
                    logger.info(f"   â”œâ”€ Taxa de Sucesso: {success_rate:.1f}% âœ… (Excelente)")
                elif success_rate >= 60:
                    logger.info(f"   â”œâ”€ Taxa de Sucesso: {success_rate:.1f}% âš ï¸ (Boa)")
                else:
                    logger.info(f"   â”œâ”€ Taxa de Sucesso: {success_rate:.1f}% âŒ (Precisa melhorar)")

                logger.info(f"   â”œâ”€ ValidaÃ§Ãµes Individuais: {stats['individual_validations']}")
                logger.info(f"   â””â”€ ValidaÃ§Ãµes Comparativas: {stats['comparative_validations']}")

                # ğŸ“ˆ SCORES MÃ‰DIOS
                logger.info("\n   ğŸ“ˆ SCORES MÃ‰DIOS:")
                avg_overall = stats['avg_overall_score']
                if avg_overall is not None:
                    if avg_overall >= 0.8:
                        logger.info(f"   â”œâ”€ Score Geral: {avg_overall:.3f} âœ… (Excelente)")
                    elif avg_overall >= 0.6:
                        logger.info(f"   â”œâ”€ Score Geral: {avg_overall:.3f} âš ï¸ (Bom)")
                    else:
                        logger.info(f"   â”œâ”€ Score Geral: {avg_overall:.3f} âŒ (Precisa melhorar)")
                else:
                    logger.info(f"   â”œâ”€ Score Geral: N/A")

                avg_consistency = stats['avg_consistency_score']
                if avg_consistency is not None:
                    logger.info(f"   â””â”€ Score ConsistÃªncia: {avg_consistency:.3f}")
                else:
                    logger.info(f"   â””â”€ Score ConsistÃªncia: N/A (sem validaÃ§Ãµes comparativas)")

                # âœ… VERIFICAÃ‡ÃƒO DE QUALIDADE
                total = stats['total_validations']
                if total > 0:
                    logger.info(f"\n   âœ… SISTEMA DE ESTATÃSTICAS FUNCIONANDO!")
                    logger.info(f"   ğŸ“ˆ {total} validaÃ§Ãµes processadas com sucesso")
                    return True
                else:
                    logger.warning(f"\n   âš ï¸ Nenhuma validaÃ§Ã£o encontrada nas estatÃ­sticas")
                    return True  # NÃ£o falhar por isso
            else:
                logger.error(f"âŒ Erro ao buscar estatÃ­sticas: {response.text}")
                return False

        except Exception as e:
            logger.error(f"âŒ Erro no teste de estatÃ­sticas: {e}")
            return False

    def run_validation_tests(self):
        """Executa todos os testes de validaÃ§Ã£o"""
        logger.info("ğŸš€ INICIANDO TESTE END-TO-END DOS ENDPOINTS DE VALIDAÃ‡ÃƒO")
        logger.info("=" * 70)

        # 1. Registrar usuÃ¡rio e fazer login
        if not self.register_user():
            return False

        if not self.login():
            return False

        # 2. Criar dataset de teste
        dataset_id = self.create_test_dataset()
        if not dataset_id:
            return False

        # 3. Criar conexÃ£o SQLite
        if not self.create_csv_connection(dataset_id):
            return False

        # 4. Criar agente
        if not self.create_test_agent():
            return False

        # 5. Criar algumas runs para testar validaÃ§Ã£o
        logger.info("\nğŸ“ CRIANDO RUNS PARA TESTE")
        logger.info("-" * 40)

        # ğŸ” PRIMEIRA QUERY - AnÃ¡lise complexa com ambiguidade temporal
        logger.info("ğŸ’¬ Criando primeira query (complexa com ambiguidade)...")
        run1 = self.send_question("Mostre os produtos mais vendidos do Ãºltimo trimestre por categoria")
        if not run1 or run1.get('status') != 'success':
            logger.error("âŒ Primeira run nÃ£o foi concluÃ­da com sucesso")
            return False
        logger.info(f"âœ… Run 1 criada: ID {run1['id']}")

        # ğŸ” SEGUNDA QUERY - Similar Ã  primeira mas com diferenÃ§as sutis
        logger.info("ğŸ’¬ Criando segunda query (similar para comparaÃ§Ã£o)...")
        run2 = self.send_question("Quais sÃ£o os produtos com maior volume de vendas por categoria no perÃ­odo recente?")
        if not run2 or run2.get('status') != 'success':
            logger.error("âŒ Segunda run nÃ£o foi concluÃ­da com sucesso")
            return False
        logger.info(f"âœ… Run 2 criada: ID {run2['id']}")

        # ğŸ” TERCEIRA QUERY - Diferente das anteriores para controle
        logger.info("ğŸ’¬ Criando terceira query (diferente para controle)...")
        run3 = self.send_question("Qual Ã© o valor total do estoque por categoria?")
        if not run3 or run3.get('status') != 'success':
            logger.error("âŒ Terceira run nÃ£o foi concluÃ­da com sucesso")
            return False
        logger.info(f"âœ… Run 3 criada: ID {run3['id']}")

        logger.info(f"âœ… Runs criadas: {[run['id'] for run in [run1, run2, run3]]}")

        # ğŸ§ª FASE 1: VALIDAÃ‡ÃƒO INDIVIDUAL DA PRIMEIRA QUERY
        logger.info("\n" + "="*70)
        logger.info("ğŸ” FASE 1: TESTANDO VALIDAÃ‡ÃƒO INDIVIDUAL (Query AmbÃ­gua)")
        logger.info("="*70)
        logger.info(f"ğŸ“ Query: '{run1.get('question', 'N/A')}'")
        logger.info(f"ğŸ¯ Expectativa: Detectar ambiguidades temporais e de critÃ©rio")

        if not self.test_validation_individual_detailed(run1['id'], "primeira"):
            return False

        # Aguardar salvamento
        logger.info("â³ Aguardando validaÃ§Ã£o ser salva no banco...")
        time.sleep(3)

        # ğŸ§ª FASE 2: VALIDAÃ‡ÃƒO INDIVIDUAL DA SEGUNDA QUERY
        logger.info("\n" + "="*70)
        logger.info("ğŸ” FASE 2: TESTANDO VALIDAÃ‡ÃƒO INDIVIDUAL (Query Similar)")
        logger.info("="*70)
        logger.info(f"ğŸ“ Query: '{run2.get('question', 'N/A')}'")
        logger.info(f"ğŸ¯ Expectativa: Detectar problemas similares Ã  primeira")

        if not self.test_validation_individual_detailed(run2['id'], "segunda"):
            return False

        # Aguardar salvamento
        logger.info("â³ Aguardando validaÃ§Ã£o ser salva no banco...")
        time.sleep(3)

        # ğŸ§ª FASE 3: VALIDAÃ‡ÃƒO COMPARATIVA ENTRE AS DUAS QUERIES
        logger.info("\n" + "="*70)
        logger.info("ğŸ” FASE 3: TESTANDO VALIDAÃ‡ÃƒO COMPARATIVA")
        logger.info("="*70)
        logger.info(f"ğŸ“ Comparando Run {run2['id']} com runs anteriores")
        logger.info(f"ğŸ¯ Expectativa: Detectar inconsistÃªncias entre queries similares")

        if not self.test_validation_comparative_detailed(run2['id']):
            return False

        # Aguardar salvamento
        logger.info("â³ Aguardando validaÃ§Ã£o ser salva no banco...")
        time.sleep(3)

        # 7. Testar listagem de validaÃ§Ãµes
        logger.info("\nğŸ” TESTANDO LISTAGEM DE VALIDAÃ‡Ã•ES")
        logger.info("=" * 50)
        if not self.test_list_validations_detailed(run1['id'], "primeira"):
            logger.warning("âš ï¸ Listagem de validaÃ§Ãµes falhou, mas continuando...")

        # ğŸ§ª FASE 5: ESTATÃSTICAS AGREGADAS
        logger.info("\n" + "="*70)
        logger.info("ğŸ” FASE 5: TESTANDO ESTATÃSTICAS AGREGADAS")
        logger.info("="*70)
        logger.info(f"ğŸ“ Verificando estatÃ­sticas de todas as validaÃ§Ãµes do usuÃ¡rio")

        if not self.test_validation_stats_detailed():
            return False

        # 9. Teste de erro - run inexistente
        logger.info("\nğŸ” TESTANDO ERRO - RUN INEXISTENTE")
        logger.info("=" * 50)

        try:
            response = requests.post(
                f"{self.base_url}/validation/runs/99999/validate",
                headers=self.get_headers(),
                json={"validation_type": "individual"}
            )

            if response.status_code == 404:
                logger.info("âœ… Erro 404 retornado corretamente para run inexistente")
            else:
                logger.error(f"âŒ Status code inesperado: {response.status_code}")
                return False

        except Exception as e:
            logger.error(f"âŒ Erro no teste de run inexistente: {e}")
            return False

        logger.info("\nğŸ‰ TODOS OS TESTES DE ENDPOINTS DE VALIDAÃ‡ÃƒO PASSARAM!")
        logger.info("âœ… Sistema de validaÃ§Ã£o funcionando corretamente via API")
        logger.info(f"ğŸ“Š Runs testadas: {len(self.run_ids)}")
        logger.info(f"ğŸ¤– Agent ID usado: {self.agent_id}")
        logger.info(f"ğŸ”— Connection ID usado: {self.connection_id}")

        return True

def main():
    """FunÃ§Ã£o principal"""
    test = ValidationEndpointsTest()

    try:
        success = test.run_validation_tests()

        if success:
            logger.info("\nğŸ‰ TESTE END-TO-END DE VALIDAÃ‡ÃƒO CONCLUÃDO COM SUCESSO!")
            logger.info("âœ… Todos os endpoints de validaÃ§Ã£o funcionando corretamente")
        else:
            logger.error("\nâŒ TESTE END-TO-END DE VALIDAÃ‡ÃƒO FALHOU!")

    except KeyboardInterrupt:
        logger.info("\nâ¹ï¸ Teste interrompido pelo usuÃ¡rio")
    except Exception as e:
        logger.error(f"\nğŸ’¥ Erro inesperado: {e}")

if __name__ == "__main__":
    main()
